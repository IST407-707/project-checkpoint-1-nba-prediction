{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4815cef-49a8-4304-84c6-b05d6ebf3994",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import pickle\n",
    "import lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f600286-2c99-4a68-b90b-ad68ff1573f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>month</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>november</td>\n",
       "      <td>invalid season link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023</td>\n",
       "      <td>january</td>\n",
       "      <td>invalid season link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023</td>\n",
       "      <td>march</td>\n",
       "      <td>invalid season link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024</td>\n",
       "      <td>april</td>\n",
       "      <td>unable to scrape table</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   season     month                   error\n",
       "0    2023  november     invalid season link\n",
       "1    2023   january     invalid season link\n",
       "2    2023     march     invalid season link\n",
       "3    2024     april  unable to scrape table"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get this data \n",
    "pd.read_parquet(\"[2022, 2023, 2024]_error.parquet.gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40d6a4a9-a6f9-4849-bea7-324c884b0b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_parquet(\"[2022, 2023, 2024]_game_stats.parquet.gzip\").to_csv(\"[2022, 2023, 2024]_game_stats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bfd26c56-6527-491c-bc4e-d0d6a01fe34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_season_schedule(filename, seasons = [2015]):\n",
    "    '''\n",
    "    Gets the season schedule (games played throughout the season) up until the playoffs.\n",
    "    creates a dataframe to inform us of any potential errors and allows code to not break because of errors\n",
    "    '''\n",
    "    season_schedule_table = pd.DataFrame(columns = [\"season\", \"date\", \"away_team_id\", \"home_team_id\", \"arena\", \"link\"])\n",
    "    # months = [\"november\", \"january\", \"march\"]\n",
    "    months = [\"april\"]\n",
    "    # [\"october\", \"november\", \"december\", \"january\", \"february\", \"march\", \"april\"]\n",
    "    \n",
    "    for year in seasons:\n",
    "        print(f\"getting {year} data....\")\n",
    "        for month in months:\n",
    "            month_schedule = f\"https://www.basketball-reference.com/leagues/NBA_{year}_games-{month}.html\"\n",
    "            print(month_schedule)\n",
    "            time.sleep(random.randint(2, 6))\n",
    "            #checks whether the link is valid and lets us know if any connections didnt work by saving to erros df. some errors here are good!\n",
    "            try:\n",
    "                month_schedule_link = urlopen(month_schedule)\n",
    "                soup = BeautifulSoup(month_schedule_link, features=\"lxml\")\n",
    "            except:\n",
    "                #the month may not have been a part of the season/year so each year will have some error months. this is really here for the covid seasons and high level error checking\n",
    "                errors = pd.DataFrame({\"season\": [year], \"month\":[month], \"error\": [\"invalid season link\"]})\n",
    "                try:\n",
    "                    name_of_file = f\"{filename}_error.csv\"\n",
    "                    errors = pd.concat([pd.read_parquet(name_of_file), errors], ignore_index = True)\n",
    "                    errors.to_parquet(name_of_file)\n",
    "                except:\n",
    "                    name_of_file = f\"{filename}_error.csv\"\n",
    "                    errors.to_parquet(name_of_file)\n",
    "                continue\n",
    "            try:\n",
    "                schedule_table = soup.find('table', attrs={'id':'schedule'})\n",
    "                games = schedule_table.tbody.findAll(\"tr\")\n",
    "                season = []\n",
    "                dates = []\n",
    "                away_team_ids = []\n",
    "                home_team_ids = []\n",
    "                arenas = []\n",
    "                links = []\n",
    "                for game in games:\n",
    "                #avoinding playoffs schedule\n",
    "                    if game.th.string == \"Playoffs\":\n",
    "                        break\n",
    "                    season.append(year)\n",
    "                    other_stats = game.findAll(\"td\")\n",
    "                    date = game.th.a.string\n",
    "                    dates.append(date)\n",
    "                    away_team = other_stats[1].a.get('href')[7:10]\n",
    "                    away_team_ids.append(away_team)\n",
    "                    home_team = other_stats[3].a.get('href')[7:10]\n",
    "                    home_team_ids.append(home_team)\n",
    "                    boxscore = other_stats[5].a.get('href')\n",
    "                    links.append(boxscore)\n",
    "                    arena = other_stats[8].string\n",
    "                    arenas.append(arena)\n",
    "                season_month = pd.DataFrame({\"season\": season,\n",
    "                                             \"date\": dates,\n",
    "                                             \"away_team_id\": away_team_ids,\n",
    "                                             \"home_team_id\": home_team_ids,\n",
    "                                              \"arena\":arenas,\n",
    "                                             \"link\":links\n",
    "                                            })\n",
    "            except:\n",
    "                #table error most likely 2020 april, where games werent played\n",
    "                errors = pd.DataFrame({\"season\": [year], \"month\":[month], \"error\": [\"unable to scrape table\"]})\n",
    "                try:\n",
    "                    name_of_file = f\"{filename}_error.csv\"\n",
    "                    errors = pd.concat([pd.read_parquet(name_of_file), errors], ignore_index = True)\n",
    "                    errors.to_parquet(name_of_file)\n",
    "                except:\n",
    "                    name_of_file = f\"{filename}_error.csv\"\n",
    "                    errors.to_parquet(name_of_file)\n",
    "                continue\n",
    "            # try to append to an existing file, if not exist create it\n",
    "            try:\n",
    "                name_of_file = f\"{filename}\"\n",
    "                season_games = pd.concat([pd.read_csv(name_of_file), season_month], ignore_index = True)\n",
    "                season_games.to_csv(name_of_file)\n",
    "            except:\n",
    "                name_of_file = f\"{filename}\"\n",
    "                season_month.to_csv(name_of_file)\n",
    "            print(month, \"completed\")\n",
    "    return pd.read_parquet(name_of_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8f6f29c7-42d4-4e13-b3fd-380fb56310ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_game_stats(dataframe, filename):\n",
    "    \"\"\"\n",
    "    gets individual game statistics given a seasons games as a pandas df\n",
    "    \"\"\"\n",
    "    count = 1\n",
    "    flag = 0\n",
    "\n",
    "    game_stats = pd.DataFrame(columns = [\"date\",\n",
    "            \"home_team\",\n",
    "            \"home_fg\",\n",
    "            \"home_fga\",\n",
    "            \"home_fg_pct\",\n",
    "            \"home_fg3\",\n",
    "            \"home_fg3a\",\n",
    "            \"home_fg3_pct\",\n",
    "            \"home_ft\",\n",
    "            \"home_fta\",\n",
    "            \"home_ft_pct\",\n",
    "            \"home_orb\",\n",
    "            \"home_drb\",\n",
    "            \"home_trb\",\n",
    "            \"home_ast\",\n",
    "            \"home_stl\",\n",
    "            \"home_blk\",\n",
    "            \"home_tov\",\n",
    "            \"home_pf\",\n",
    "            \"home_pts\",\n",
    "            \"away_team\",\n",
    "            \"away_fg\",\n",
    "            \"away_fga\",\n",
    "            \"away_fg_pct\",\n",
    "            \"away_fg3\",\n",
    "            \"away_fg3a\",\n",
    "            \"away_fg3_pct\",\n",
    "            \"away_ft\",\n",
    "            \"away_fta\",\n",
    "            \"away_ft_pct\",\n",
    "            \"away_orb\",\n",
    "            \"away_drb\",\n",
    "            \"away_trb\",\n",
    "            \"away_ast\",\n",
    "            \"away_stl\",\n",
    "            \"away_blk\",\n",
    "            \"away_tov\",\n",
    "            \"away_pf\",\n",
    "            \"away_pts\",\n",
    "            \"arena\"])\n",
    "    \n",
    "    print(\"getitng individual game stats\", end = \" \")\n",
    "\n",
    "    for game in dataframe.iterrows():\n",
    "        print('.', end=\"\")\n",
    "        game = game[1]\n",
    "        home_team_id = game[\"home_team_id\"]\n",
    "        away_team_id = game[\"away_team_id\"]\n",
    "        arena = game[\"arena\"]\n",
    "        ext = game[\"link\"]\n",
    "        this_season = game[\"season\"]\n",
    "        try:\n",
    "            box_score_url = f\"https://www.basketball-reference.com{ext}\"\n",
    "            time.sleep(random.randint(5, 10))\n",
    "            open_link = urlopen(box_score_url)\n",
    "            soup = BeautifulSoup(open_link, features=\"lxml\")\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            error = pd.DataFrame({\"season\": game[\"season\"],\n",
    "            \"date\": game[\"date\"],\n",
    "            \"away_team_id\": away_team_id,\n",
    "            \"home_team_id\": home_team_id,\n",
    "            \"arena\": arena,\n",
    "            \"link\": ext,\n",
    "            \"error\": [\"404: invalid game link\"]})\n",
    "            try:\n",
    "                name_of_file = f\"{filename}_error.csv\"\n",
    "                errors = pd.concat([pd.read_parquet(name_of_file), error], ignore_index = True)\n",
    "                errors.to_csv(name_of_file)\n",
    "            except:\n",
    "                name_of_file = f\"{filename}_error.csv\"\n",
    "                error.to_csv(name_of_file)\n",
    "            continue\n",
    "        try:\n",
    "            home_stats = soup.find('table', attrs={'id':f\"box-{home_team_id}-game-basic\"}).tfoot.tr\n",
    "            home_fg = home_stats.find('td', attrs = {'data-stat': 'fg'}).string\n",
    "            home_fga = home_stats.find('td', attrs = {'data-stat': 'fga'}).string\n",
    "            home_fg_pct = home_stats.find('td', attrs = {'data-stat': 'fg_pct'}).string\n",
    "            home_fg3 = home_stats.find('td', attrs = {'data-stat': 'fg3'}).string\n",
    "            home_fg3a = home_stats.find('td', attrs = {'data-stat': 'fg3a'}).string\n",
    "            home_fg3_pct = home_stats.find('td', attrs = {'data-stat': 'fg3_pct'}).string\n",
    "            home_ft = home_stats.find('td', attrs = {'data-stat': 'ft'}).string\n",
    "            home_fta = home_stats.find('td', attrs = {'data-stat': 'fta'}).string\n",
    "            home_ft_pct = home_stats.find('td', attrs = {'data-stat': 'ft_pct'}).string\n",
    "            home_orb = home_stats.find('td', attrs = {'data-stat': 'orb'}).string\n",
    "            home_drb = home_stats.find('td', attrs = {'data-stat': 'drb'}).string\n",
    "            home_trb = home_stats.find('td', attrs = {'data-stat': 'trb'}).string\n",
    "            home_ast = home_stats.find('td', attrs = {'data-stat': 'ast'}).string\n",
    "            home_stl = home_stats.find('td', attrs = {'data-stat': 'stl'}).string\n",
    "            home_blk = home_stats.find('td', attrs = {'data-stat': 'blk'}).string\n",
    "            home_tov = home_stats.find('td', attrs = {'data-stat': 'tov'}).string\n",
    "            home_pf = home_stats.find('td', attrs = {'data-stat': 'pf'}).string\n",
    "            home_pts = home_stats.find('td', attrs = {'data-stat': 'pts'}).string\n",
    "\n",
    "            away_stats = soup.find('table', attrs={'id':f\"box-{away_team_id}-game-basic\"}).tfoot.tr\n",
    "            away_fg = away_stats.find('td', attrs = {'data-stat': 'fg'}).string\n",
    "            away_fga = away_stats.find('td', attrs = {'data-stat': 'fga'}).string\n",
    "            away_fg_pct = away_stats.find('td', attrs = {'data-stat': 'fg_pct'}).string\n",
    "            away_fg3 = away_stats.find('td', attrs = {'data-stat': 'fg3'}).string\n",
    "            away_fg3a = away_stats.find('td', attrs = {'data-stat': 'fg3a'}).string\n",
    "            away_fg3_pct = away_stats.find('td', attrs = {'data-stat': 'fg3_pct'}).string\n",
    "            away_ft = away_stats.find('td', attrs = {'data-stat': 'ft'}).string\n",
    "            away_fta = away_stats.find('td', attrs = {'data-stat': 'fta'}).string\n",
    "            away_ft_pct = away_stats.find('td', attrs = {'data-stat': 'ft_pct'}).string\n",
    "            away_orb = away_stats.find('td', attrs = {'data-stat': 'orb'}).string\n",
    "            away_drb = away_stats.find('td', attrs = {'data-stat': 'drb'}).string\n",
    "            away_trb = away_stats.find('td', attrs = {'data-stat': 'trb'}).string\n",
    "            away_ast = away_stats.find('td', attrs = {'data-stat': 'ast'}).string\n",
    "            away_stl = away_stats.find('td', attrs = {'data-stat': 'stl'}).string\n",
    "            away_blk = away_stats.find('td', attrs = {'data-stat': 'blk'}).string\n",
    "            away_tov = away_stats.find('td', attrs = {'data-stat': 'tov'}).string\n",
    "            away_pf = away_stats.find('td', attrs = {'data-stat': 'pf'}).string\n",
    "            away_pts = away_stats.find('td', attrs = {'data-stat': 'pts'}).string\n",
    "\n",
    "            this_game_stats = pd.DataFrame({\n",
    "            \"date\": [game[\"date\"]],\n",
    "            \"home_team\":[home_team_id],\n",
    "            \"home_fg\":[home_fg],\n",
    "            \"home_fga\":[home_fga],\n",
    "            \"home_fg_pct\":[home_fg_pct],\n",
    "            \"home_fg3\":[home_fg3],\n",
    "            \"home_fg3a\":[home_fg3a],\n",
    "            \"home_fg3_pct\":[home_fg3_pct],\n",
    "            \"home_ft\":[home_ft],\n",
    "            \"home_fta\":[home_fta],\n",
    "            \"home_ft_pct\":[home_ft_pct],\n",
    "            \"home_orb\":[home_orb],\n",
    "            \"home_drb\":[home_drb],\n",
    "            \"home_trb\":[home_trb],\n",
    "            \"home_ast\":[home_ast],\n",
    "            \"home_stl\":[home_stl],\n",
    "            \"home_blk\":[home_blk],\n",
    "            \"home_tov\":[home_tov],\n",
    "            \"home_pf\":[home_pf],\n",
    "            \"home_pts\":[home_pts],\n",
    "            \"away_team\":[away_team_id],\n",
    "            \"away_fg\":[away_fg],\n",
    "            \"away_fga\":[away_fga],\n",
    "            \"away_fg_pct\":[away_fg_pct],\n",
    "            \"away_fg3\":[away_fg3],\n",
    "            \"away_fg3a\":[away_fg3a],\n",
    "            \"away_fg3_pct\":[away_fg3_pct],\n",
    "            \"away_ft\":[away_ft],\n",
    "            \"away_fta\":[away_fta],\n",
    "            \"away_ft_pct\":[away_ft_pct],\n",
    "            \"away_orb\":[away_orb],\n",
    "            \"away_drb\":[away_drb],\n",
    "            \"away_trb\":[away_trb],\n",
    "            \"away_ast\":[away_ast],\n",
    "            \"away_stl\":[away_stl],\n",
    "            \"away_blk\":[away_blk],\n",
    "            \"away_tov\":[away_tov],\n",
    "            \"away_pf\":[away_pf],\n",
    "            \"away_pts\":[away_pts],\n",
    "            \"arena\": [arena]})\n",
    "            \n",
    "            game_stats = pd.concat([game_stats, this_game_stats], ignore_index = True)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            error = pd.DataFrame({\"season\": game[\"season\"],\n",
    "            \"date\": game[\"date\"],\n",
    "            \"away_team_id\": away_team_id,\n",
    "            \"home_team_id\": home_team_id,\n",
    "            \"arena\": arena,\n",
    "            \"link\": ext,\n",
    "            \"error\": [\"error scraping table\"]})\n",
    "            flag = 1\n",
    "            try:\n",
    "                name_of_file = f\"{filename}_error.csv\"\n",
    "                errors = pd.concat([pd.read_parquet(name_of_file), error], ignore_index = True)\n",
    "                errors.to_csv(name_of_file)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                name_of_file = f\"{filename}_error.csv\"\n",
    "                error.to_csv(name_of_file)\n",
    "            continue\n",
    "\n",
    "\n",
    "    if count % 100 == 0:\n",
    "        name_of_file = f\"{filename}.csv\"\n",
    "        try:\n",
    "            existing_df = pd.read_csv(name_of_file)\n",
    "            combined_df = pd.concat([game_stats, existing_df], ignore_index = True)\n",
    "            combined_df.to_csv(name_of_file)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            game_stats.to_csv(name_of_file)\n",
    "       \n",
    "        scraped = len(pd.read_csv(name_of_file))\n",
    "        print(f\"\\nstats scraped from {scraped} of {len(dataframe)} in {this_season}\")\n",
    "        game_stats = pd.DataFrame(columns = game_stats.columns)\n",
    "\n",
    "        \n",
    "    if count == len(dataframe):\n",
    "        name_of_file = f\"{filename}.csv\"\n",
    "        existing_df = pd.read_csv(name_of_file)\n",
    "        combined_df = pd.concat([game_stats, existing_df], ignore_index = True)\n",
    "        combined_df.to_csv(name_of_file)\n",
    "    count+=1\n",
    "\n",
    "    if flag == 1:\n",
    "        print(\"errors: \", len(pd.read_csv(f\"{filename}_error.csv\")))\n",
    "    return game_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9ed1ce-a6d6-4357-906c-8c7ca324f96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_season_schedule(\"[2024]\", [2024])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e317ee-c4fe-4d74-97b5-c26c685210c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882aaa96-c355-4315-8f53-de3cc78227de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getitng individual game stats ........................................................................................................................................................................................................................................................................"
     ]
    }
   ],
   "source": [
    "schedule_2023 = pd.read_parquet(\"[2023].parquet.gzip\")\n",
    "get_game_stats(schedule_2023, \"missing_2023_gs\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
