{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e998b61-6a34-4975-8ebe-2100642a6e3a",
   "metadata": {},
   "source": [
    "# Process of scraping and generating data for nba seasons 2015+"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac13fd6-5973-4fe7-a6e2-22bc566360e0",
   "metadata": {},
   "source": [
    "get season rosters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "51524812-b23a-4cca-bde8-21c761774da9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd \n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import pickle\n",
    "import lxml\n",
    "from datetime import datetime\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a536fd77-ac97-4c6e-bafc-a25d87034bb6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def team_roster_base(years = [2015]):\n",
    "    team_roster_base = pd.DataFrame(columns = [\"Year\", \"Team\", \"team_dir\"])\n",
    "    # loop through each year\n",
    "    for y in years:\n",
    "        # NBA season to scrape- year is season end so 2015 is 2014-15 season \n",
    "        year = y\n",
    "        url = f\"https://www.basketball-reference.com/leagues/NBA_{year}_ratings.html\"\n",
    "        html = urlopen(url)\n",
    "        soup = BeautifulSoup(html, features=\"lxml\")\n",
    "        table = soup.find('table', attrs={'id':'ratings'})\n",
    "        teams = table.tbody.findAll(\"tr\")\n",
    "        for team in teams: #get team names and links - would get stats here as well\n",
    "            team_name= team.td.string\n",
    "            team_dir = team.td.a.get('href')\n",
    "            team_year= {\"Year\": year, \"Team\": team_name, \"team_dir\": team_dir}\n",
    "            team_roster_base = pd.concat([team_roster_base, pd.DataFrame([team_year])], ignore_index=True)\n",
    "        time.sleep(5)\n",
    "    return team_roster_base\n",
    "\n",
    "def team_roster_base_u():\n",
    "    team_roster_base = pd.read_csv(\"team_roster_base.csv\")\n",
    "    team_roster_base = team_roster_base[[\"Year\", \"Team\", \"team_dir\"]]\n",
    "    today = date.today()\n",
    "    today_year, today_month, today_day= today.year, today.month, today.day\n",
    "   \n",
    "    if team_roster_base[\"Year\"].max() < today_year:\n",
    "        lag = today_year - team_roster_base[\"Year\"].max()\n",
    "        years = []\n",
    "        for i in range(1, lag+1):\n",
    "            years.append(team_roster_base[\"Year\"].max()+i)\n",
    "\n",
    "        # loop through each year\n",
    "        for y in years:\n",
    "            # NBA season to scrape- year is season end so 2015 is 2014-15 season \n",
    "            year = y\n",
    "            url = f\"https://www.basketball-reference.com/leagues/NBA_{year}_ratings.html\"\n",
    "            html = urlopen(url)\n",
    "            soup = BeautifulSoup(html, features=\"lxml\")\n",
    "            table = soup.find('table', attrs={'id':'ratings'})\n",
    "            teams = table.tbody.findAll(\"tr\")\n",
    "            for team in teams: #get team names and links - would get stats here as well\n",
    "                team_name= team.td.string\n",
    "                team_dir = team.td.a.get('href')\n",
    "                team_year= {\"Year\": year, \"Team\": team_name, \"team_dir\": team_dir}\n",
    "                team_roster_base = pd.concat([team_roster_base, pd.DataFrame([team_year])], ignore_index=True)\n",
    "            time.sleep(5)\n",
    "    team_roster_base = team_roster_base[[\"Year\", \"Team\", \"team_dir\"]]\n",
    "    team_roster_base.to_csv(\"team_roster_base.csv\")\n",
    "    return team_roster_base[[\"Year\", \"Team\", \"team_dir\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b57ee6d3-08d8-4dcb-b7ec-5a53164605af",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_rosters(team_roster_base):\n",
    "    yearly_rosters = pd.DataFrame(columns = [\"Year\", \"Team\", \"team_dir\", \"Player\", \"player_dir\"])\n",
    "    base_url = \"https://www.basketball-reference.com\"\n",
    "    for index, row in team_roster_base.iterrows():\n",
    "        roster_url = base_url+str(row['team_dir'])\n",
    "        time.sleep(random.randint(3, 9))\n",
    "        html_team = urlopen(roster_url)\n",
    "        soup = BeautifulSoup(html_team, features=\"lxml\")\n",
    "        roster_table = soup.find('table', attrs={'id':'roster'})\n",
    "        players = roster_table.tbody.findAll(\"tr\")\n",
    "        year = [str(row['Year'])]\n",
    "        team = [str(row['Team'])]\n",
    "        team_dir = [str(row['team_dir'])]\n",
    "        for player in players:\n",
    "            player_name = [str(player.td.string)]\n",
    "            player_dir = [str(player.td.a.get('href'))]\n",
    "            team_year_player = pd.DataFrame({\"Year\": year,\n",
    "                                             \"Team\": team, \n",
    "                                             \"team_dir\": team_dir, \n",
    "                                             \"Player\": player_name, \n",
    "                                             \"player_dir\": player_dir})\n",
    "            yearly_rosters = pd.concat([yearly_rosters, team_year_player], ignore_index = True)\n",
    "    return yearly_rosters\n",
    "\n",
    "def get_rosters_u():\n",
    "    today = date.today()\n",
    "    today_year, today_month, today_day= today.year, today.month, today.day\n",
    "    yearly_rosters = pd.read_csv('season_rosters.csv')[[\"Year\",\"Team\",\"team_dir\",\"Player\", \"player_dir\"]]\n",
    "    team_roster_base = pd.read_csv(\"team_roster_base.csv\")[[\"Year\", \"Team\", \"team_dir\"]]\n",
    "    \n",
    "    if yearly_rosters[\"Year\"].max() < today_year:\n",
    "        lag = today_year - team_roster_base[\"Year\"].max()\n",
    "        years = []\n",
    "        for i in range(1, lag+1):\n",
    "            years.append(yearly_rosters[\"Year\"].max()+i)\n",
    "        \n",
    "            \n",
    "        team_roster_base = team_roster_base[team_roster_base[\"Year\"].isin(years)]\n",
    "    else:\n",
    "        team_roster_base = team_roster_base[team_roster_base[\"Year\"]==today_year]\n",
    "        \n",
    "    base_url = \"https://www.basketball-reference.com\"\n",
    "    for index, row in team_roster_base.iterrows():\n",
    "        print('\\n', row, end = \"\")\n",
    "        roster_url = base_url+str(row['team_dir'])\n",
    "        time.sleep(random.randint(3, 7))\n",
    "        html_team = urlopen(roster_url)\n",
    "        soup = BeautifulSoup(html_team, features=\"lxml\")\n",
    "        roster_table = soup.find('table', attrs={'id':'roster'})\n",
    "        players = roster_table.tbody.findAll(\"tr\")\n",
    "        year = [str(row['Year'])]\n",
    "        team = [str(row['Team'])]\n",
    "        team_dir = [str(row['team_dir'])]\n",
    "        for player in players:\n",
    "            print(\".\", end = \"\")\n",
    "            player_name = [str(player.td.string)]\n",
    "            player_dir = [str(player.td.a.get('href'))]\n",
    "            team_year_player = pd.DataFrame({\"Year\": year,\n",
    "                                             \"Team\": team, \n",
    "                                             \"team_dir\": team_dir, \n",
    "                                             \"Player\": player_name, \n",
    "                                             \"player_dir\": player_dir})\n",
    "            yearly_rosters = pd.concat([yearly_rosters, team_year_player], ignore_index = True)\n",
    "    yearly_rosters = yearly_rosters.drop_duplicates(subset=['Year', 'Team', 'Player'])\n",
    "    yearly_rosters.to_csv('season_rosters.csv')\n",
    "    return yearly_rosters.drop_duplicates(subset=['Year', 'Team', 'Player'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c22df68f-b136-4407-920a-6a23f31e48c2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_pers(season_rosters, filename):\n",
    "    #get player efficiency ratings \n",
    "    progress = 0 \n",
    "    per_table = pd.DataFrame(columns = [\"season\", \"team_id\", \"player_dir\", \"per\"])\n",
    "    players_list = []\n",
    "    for index, row in season_rosters.iterrows():\n",
    "        progress+= 1\n",
    "        season = str(int(row['Year'])-1)+'-'+row['Year'][2:]\n",
    "        team = row['team_dir'][7:10]\n",
    "        base_url = \"https://www.basketball-reference.com\"\n",
    "        player_url = base_url+str(row['player_dir'])\n",
    "        if row['player_dir'] in players_list:\n",
    "            continue\n",
    "        else:\n",
    "            players_list.append(row['player_dir'])\n",
    "        try:\n",
    "            time.sleep(random.randint(3, 9))\n",
    "            html_player = urlopen(player_url)\n",
    "            player_seasons = []\n",
    "            player_team_ids = []\n",
    "            # player_team_dirs = []\n",
    "            player_dirs = []\n",
    "            player_pers = []\n",
    "            soup = BeautifulSoup(html_player, features=\"lxml\")\n",
    "            adv_table = soup.find('table', attrs={'id':'advanced'})\n",
    "            teams = adv_table.tbody.findAll(\"tr\")\n",
    "            for team in teams:\n",
    "                # th is season td is all other stats \n",
    "                player_seasons.append(str(team.th.a.string))\n",
    "                # print(player_seasons)\n",
    "                other_stats = team.findAll('td')\n",
    "                team_id = other_stats[1].string\n",
    "                player_team_ids.append(str(team_id))\n",
    "                # player_team_dirs.append(row['team_dir'])\n",
    "                player_dirs.append(row['player_dir'])\n",
    "                per_value = other_stats[6].string\n",
    "                player_pers.append(per_value)\n",
    "            this_player = pd .DataFrame({ \"season\": player_seasons,\n",
    "                                         \"team_id\": player_team_ids, \n",
    "                                         \"player_dir\": player_dirs, \n",
    "                                         \"per\":player_pers})\n",
    "            per_table = pd.concat([per_table, this_player], ignore_index = True)\n",
    "        except:\n",
    "            print(row)\n",
    "        \n",
    "    # https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_parquet.html\n",
    "    per_table.to_parquet(f'{filename}.parquet.gzip', compression='gzip')\n",
    "    return per_table\n",
    "\n",
    "def get_pers_u():\n",
    "    #get player efficiency ratings \n",
    "    progress = 0 \n",
    "    season_rosters = pd.read_csv('season_rosters.csv')[[\"Year\",\"Team\",\"team_dir\",\"Player\", \"player_dir\"]]\n",
    "    per_table = pd.read_csv(\"player_ERs.csv\")\n",
    "    season_rosters['team_id'] = season_rosters['team_dir'].str.extract(r'/teams/(\\w{3})/')\n",
    "    season_rosters['season'] = (season_rosters['Year'] + -1).astype(str) + '-' + (season_rosters['Year']).astype(str).str.slice(2, 4)\n",
    "    season_rosters.drop_duplicates(subset=['season', 'team_id', 'player_dir']).sort_values(by='player_dir')\n",
    "    per_table = pd.read_csv(\"player_ERs.csv\")\n",
    "    per_table = per_table[per_table['team_id']!= 'TOT']\n",
    "    per_table.drop_duplicates(subset=['season', 'team_id', 'player_dir']).sort_values(by='player_dir')\n",
    "    merged_df = pd.merge(season_rosters, per_table, on=['season', 'team_id', 'player_dir'], how='outer', indicator=True)\n",
    "    unmatched_rows = merged_df[merged_df['_merge'] == 'left_only'][[\"Year\",\"Team\",\"team_dir\",\"Player\", \"player_dir\"]]\n",
    "    \n",
    "    players_list = []\n",
    "    \n",
    "    for index, row in unmatched_rows.iterrows():\n",
    "        progress+= 1\n",
    "        if progress % len(unmatched_rows) == 0:\n",
    "            print(round(progress/len(unmatched_rows), 4), \"%\", end='\\t')\n",
    "        season = str(int(row['Year']) - 1) + '-' + str(row['Year'])[2:]\n",
    "        team = row['team_dir'][7:10]\n",
    "        base_url = \"https://www.basketball-reference.com\"\n",
    "        player_url = base_url+str(row['player_dir'])\n",
    "        if row['player_dir'] in players_list:\n",
    "            continue\n",
    "        else:\n",
    "            players_list.append(row['player_dir'])\n",
    "        try:\n",
    "            time.sleep(random.randint(3, 7))\n",
    "            html_player = urlopen(player_url)\n",
    "            player_seasons = []\n",
    "            player_team_ids = []\n",
    "            # player_team_dirs = []\n",
    "            player_dirs = []\n",
    "            player_pers = []\n",
    "            soup = BeautifulSoup(html_player, features=\"lxml\")\n",
    "            adv_table = soup.find('table', attrs={'id':'advanced'})\n",
    "            teams = adv_table.tbody.findAll(\"tr\")\n",
    "            for team in teams:\n",
    "                # th is season td is all other stats \n",
    "                player_seasons.append(str(team.th.a.string))\n",
    "                # print(player_seasons)\n",
    "                other_stats = team.findAll('td')\n",
    "                team_id = other_stats[1].string\n",
    "                player_team_ids.append(str(team_id))\n",
    "                # player_team_dirs.append(row['team_dir'])\n",
    "                player_dirs.append(row['player_dir'])\n",
    "                per_value = other_stats[6].string\n",
    "                player_pers.append(per_value)\n",
    "            this_player = pd .DataFrame({ \"season\": player_seasons,\n",
    "                                         \"team_id\": player_team_ids, \n",
    "                                         \"player_dir\": player_dirs, \n",
    "                                         \"per\":player_pers})\n",
    "            per_table = pd.concat([per_table, this_player], ignore_index = True)\n",
    "        except:\n",
    "            print(row)\n",
    "        \n",
    "    # https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_parquet.html\n",
    "    per_table.to_csv(\"player_ERs.csv\")\n",
    "    return per_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "704350d1-0766-4b73-856b-3602f44c2cc0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_season_schedule(filename, seasons = [2015]):\n",
    "    '''\n",
    "    Gets the season schedule (games played throughout the season) up until the playoffs.\n",
    "    creates a dataframe to inform us of any potential errors and allows code to not break because of errors\n",
    "    '''\n",
    "    season_schedule_table = pd.DataFrame(columns = [\"season\", \"date\", \"away_team_id\", \"home_team_id\", \"arena\", \"link\"])\n",
    "    months = [\"october\", \"november\", \"december\", \"january\", \"february\", \"march\", \"april\"]\n",
    "    name_of_error_file = f\"{filename}_error.csv\"\n",
    "    for year in seasons:\n",
    "        print(f\"getting {year} data....\")\n",
    "        for month in months:\n",
    "            month_schedule = f\"https://www.basketball-reference.com/leagues/NBA_{year}_games-{month}.html\"\n",
    "            print(month_schedule)\n",
    "            time.sleep(random.randint(2, 6))\n",
    "            #checks whether the link is valid and lets us know if any connections didnt work by saving to erros df. some errors here are good!\n",
    "            try:\n",
    "                month_schedule_link = urlopen(month_schedule)\n",
    "                soup = BeautifulSoup(month_schedule_link, features=\"lxml\")\n",
    "            except:\n",
    "                #the month may not have been a part of the season/year so each year will have some error months. this is really here for the covid seasons and high level error checking\n",
    "                error_new = pd.DataFrame({\"season\": [year], \"month\":[month], \"error\": [\"invalid season link\"]})\n",
    "                try:\n",
    "                    errors = pd.concat([errors, error_new], ignore_index = True)\n",
    "                except:\n",
    "                    errors = error_new\n",
    "                continue\n",
    "            try:\n",
    "                schedule_table = soup.find('table', attrs={'id':'schedule'})\n",
    "                games = schedule_table.tbody.findAll(\"tr\")\n",
    "                season = []\n",
    "                dates = []\n",
    "                away_team_ids = []\n",
    "                home_team_ids = []\n",
    "                arenas = []\n",
    "                links = []\n",
    "                for game in games:\n",
    "                #avoinding playoffs schedule\n",
    "                    if game.th.string == \"Playoffs\":\n",
    "                        break\n",
    "                    season.append(year)\n",
    "                    other_stats = game.findAll(\"td\")\n",
    "                    date = game.th.a.string\n",
    "                    dates.append(date)\n",
    "                    away_team = other_stats[1].a.get('href')[7:10]\n",
    "                    away_team_ids.append(away_team)\n",
    "                    home_team = other_stats[3].a.get('href')[7:10]\n",
    "                    home_team_ids.append(home_team)\n",
    "                    boxscore = other_stats[5].a.get('href')\n",
    "                    links.append(boxscore)\n",
    "                    arena = other_stats[8].string\n",
    "                    arenas.append(arena)\n",
    "                season_month = pd.DataFrame({\"season\": season,\n",
    "                                             \"date\": dates,\n",
    "                                             \"away_team_id\": away_team_ids,\n",
    "                                             \"home_team_id\": home_team_ids,\n",
    "                                              \"arena\":arenas,\n",
    "                                             \"link\":links\n",
    "                                            })\n",
    "            except:\n",
    "                #table error most likely 2020 april, where games werent played\n",
    "                error_new = pd.DataFrame({\"season\": [year], \"month\":[month], \"error\": [\"unable to scrape table\"]})\n",
    "                try:\n",
    "                    errors = pd.concat([errors, error_new], ignore_index = True)\n",
    "                except:\n",
    "                    errors = error_new\n",
    "                continue\n",
    "            # try to append to an existing file, if not exist create it\n",
    "            try:\n",
    "                season_games = pd.concat([season_games, season_month], ignore_index = True)\n",
    "            except:\n",
    "                season_games = season_month\n",
    "            print(month, \"completed\")\n",
    "    season_games.to_csv(file_name+\".csv\")\n",
    "    errors.to_csv(name_of_error_file)\n",
    "    return season_games\n",
    "\n",
    "def convert_date(date_string):\n",
    "    date_object = datetime.strptime(date_string, \"%a, %b %d, %Y\")\n",
    "    formatted_date = date_object.strftime(\"%Y-%m-%d\")\n",
    "    return formatted_date\n",
    "\n",
    "def season_schedule_u():\n",
    "    # Load initial season schedules\n",
    "    season_schedules = pd.read_csv('season_schedules.csv')[['season', 'date', 'away_team_id', 'home_team_id', 'arena', 'link']]\n",
    "    \n",
    "    # Initialize errors DataFrame\n",
    "    errors = pd.DataFrame(columns=[\"season\", \"month\", \"error\"])\n",
    "    \n",
    "    # Get current date\n",
    "    today_date = datetime.today()\n",
    "    today_year, today_month = today_date.year, today_date.month\n",
    "    \n",
    "    months_array = [\"may\", \"june\", \"july\", \"august\", \"september\", \"october\", \"november\", \"december\", \"january\", \"february\", \"march\", \"april\"]\n",
    "    ss_month\n",
    "    \n",
    "    # Loop over years and months\n",
    "    for year in range(int(season_schedules['date'].max()[0:4]), today_year + 1):\n",
    "        for month in months_array[(ss_month+7%12)+1:]: #loop over months\n",
    "            print(month)\n",
    "            month_schedule = f\"https://www.basketball-reference.com/leagues/NBA_{year}_games-{month}.html\"\n",
    "            month_schedule_link = urlopen(month_schedule)\n",
    "            soup = BeautifulSoup(month_schedule_link, features=\"lxml\")\n",
    "            schedule_table = soup.find('table', attrs={'id': 'schedule'})\n",
    "            games = schedule_table.tbody.findAll(\"tr\")\n",
    "            season = []\n",
    "            dates = []\n",
    "            away_team_ids = []\n",
    "            home_team_ids = []\n",
    "            arenas = []\n",
    "            links = []\n",
    "            for game in games:\n",
    "                if game.th.string == \"Playoffs\":\n",
    "                    break\n",
    "                date = game.th.a.string\n",
    "                date_object =  datetime.strptime(date, \"%a, %b %d, %Y\")\n",
    "                if \"april\" == date_object.strftime(\"%B\").lower():\n",
    "                    if int(date_object.strftime(\"%d\")) > 14: #2023-24 regular season\n",
    "                        season_month = pd.DataFrame({\"season\": season,\n",
    "                                                     \"date\": dates,\n",
    "                                                     \"away_team_id\": away_team_ids,\n",
    "                                                     \"home_team_id\": home_team_ids,\n",
    "                                                      \"arena\":arenas,\n",
    "                                                     \"link\":links})\n",
    "                        season_schedules = pd.concat([season_schedules, season_month], ignore_index=True)\n",
    "                        season_schedules['date'] = season_schedules['date'].apply(lambda x: convert_date(x) if ',' in x else x)\n",
    "                        season_schedules = season_schedules[['season', 'date', 'away_team_id', 'home_team_id', 'arena', 'link']].drop_duplicates(subset=['link'])\n",
    "                        season_schedules.to_csv(\"season_schedules.csv\", index=False)\n",
    "                        break\n",
    "                season.append(year)\n",
    "                other_stats = game.findAll(\"td\")\n",
    "                dates.append(date)\n",
    "                away_team = str(other_stats[1].a.get('href'))[7:10]\n",
    "                away_team_ids.append(away_team)\n",
    "                home_team = str(other_stats[3].a.get('href'))[7:10]\n",
    "                home_team_ids.append(home_team)\n",
    "                boxscore = other_stats[5].a.get('href')\n",
    "                links.append(boxscore)\n",
    "                arena = other_stats[8].string\n",
    "                arenas.append(arena)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "93c246d5-e80a-4def-9f17-f7fd5b72022b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_game_stats(dataframe, filename):\n",
    "    \"\"\"\n",
    "    gets individual game statistics given a seasons games as a pandas df\n",
    "    \"\"\"\n",
    "    count = 1\n",
    "    flag = 0\n",
    "\n",
    "    game_stats = pd.DataFrame(columns = [\"date\",\n",
    "            \"home_team\",\n",
    "            \"home_fg\",\n",
    "            \"home_fga\",\n",
    "            \"home_fg_pct\",\n",
    "            \"home_fg3\",\n",
    "            \"home_fg3a\",\n",
    "            \"home_fg3_pct\",\n",
    "            \"home_ft\",\n",
    "            \"home_fta\",\n",
    "            \"home_ft_pct\",\n",
    "            \"home_orb\",\n",
    "            \"home_drb\",\n",
    "            \"home_trb\",\n",
    "            \"home_ast\",\n",
    "            \"home_stl\",\n",
    "            \"home_blk\",\n",
    "            \"home_tov\",\n",
    "            \"home_pf\",\n",
    "            \"home_pts\",\n",
    "            \"away_team\",\n",
    "            \"away_fg\",\n",
    "            \"away_fga\",\n",
    "            \"away_fg_pct\",\n",
    "            \"away_fg3\",\n",
    "            \"away_fg3a\",\n",
    "            \"away_fg3_pct\",\n",
    "            \"away_ft\",\n",
    "            \"away_fta\",\n",
    "            \"away_ft_pct\",\n",
    "            \"away_orb\",\n",
    "            \"away_drb\",\n",
    "            \"away_trb\",\n",
    "            \"away_ast\",\n",
    "            \"away_stl\",\n",
    "            \"away_blk\",\n",
    "            \"away_tov\",\n",
    "            \"away_pf\",\n",
    "            \"away_pts\",\n",
    "            \"arena\"])\n",
    "    \n",
    "    print(\"getitng individual game stats\", end = \" \")\n",
    "\n",
    "    for game in dataframe.iterrows():\n",
    "        print('.', end=\"\")\n",
    "        game = game[1]\n",
    "        home_team_id = game[\"home_team_id\"]\n",
    "        away_team_id = game[\"away_team_id\"]\n",
    "        arena = game[\"arena\"]\n",
    "        ext = game[\"link\"]\n",
    "        this_season = game[\"season\"]\n",
    "        try:\n",
    "            box_score_url = f\"https://www.basketball-reference.com{ext}\"\n",
    "            time.sleep(random.randint(5, 10))\n",
    "            open_link = urlopen(box_score_url)\n",
    "            soup = BeautifulSoup(open_link, features=\"lxml\")\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            error_new = pd.DataFrame({\"season\": game[\"season\"],\n",
    "            \"date\": game[\"date\"],\n",
    "            \"away_team_id\": away_team_id,\n",
    "            \"home_team_id\": home_team_id,\n",
    "            \"arena\": arena,\n",
    "            \"link\": ext,\n",
    "            \"error\": [\"404: invalid game link\"]})\n",
    "            try:\n",
    "                errors = pd.concat([errors, error_new], ignore_index = True)\n",
    "            except:\n",
    "                errors = error_new\n",
    "            continue\n",
    "        try:\n",
    "            home_stats = soup.find('table', attrs={'id':f\"box-{home_team_id}-game-basic\"}).tfoot.tr\n",
    "            home_fg = home_stats.find('td', attrs = {'data-stat': 'fg'}).string\n",
    "            home_fga = home_stats.find('td', attrs = {'data-stat': 'fga'}).string\n",
    "            home_fg_pct = home_stats.find('td', attrs = {'data-stat': 'fg_pct'}).string\n",
    "            home_fg3 = home_stats.find('td', attrs = {'data-stat': 'fg3'}).string\n",
    "            home_fg3a = home_stats.find('td', attrs = {'data-stat': 'fg3a'}).string\n",
    "            home_fg3_pct = home_stats.find('td', attrs = {'data-stat': 'fg3_pct'}).string\n",
    "            home_ft = home_stats.find('td', attrs = {'data-stat': 'ft'}).string\n",
    "            home_fta = home_stats.find('td', attrs = {'data-stat': 'fta'}).string\n",
    "            home_ft_pct = home_stats.find('td', attrs = {'data-stat': 'ft_pct'}).string\n",
    "            home_orb = home_stats.find('td', attrs = {'data-stat': 'orb'}).string\n",
    "            home_drb = home_stats.find('td', attrs = {'data-stat': 'drb'}).string\n",
    "            home_trb = home_stats.find('td', attrs = {'data-stat': 'trb'}).string\n",
    "            home_ast = home_stats.find('td', attrs = {'data-stat': 'ast'}).string\n",
    "            home_stl = home_stats.find('td', attrs = {'data-stat': 'stl'}).string\n",
    "            home_blk = home_stats.find('td', attrs = {'data-stat': 'blk'}).string\n",
    "            home_tov = home_stats.find('td', attrs = {'data-stat': 'tov'}).string\n",
    "            home_pf = home_stats.find('td', attrs = {'data-stat': 'pf'}).string\n",
    "            home_pts = home_stats.find('td', attrs = {'data-stat': 'pts'}).string\n",
    "\n",
    "            away_stats = soup.find('table', attrs={'id':f\"box-{away_team_id}-game-basic\"}).tfoot.tr\n",
    "            away_fg = away_stats.find('td', attrs = {'data-stat': 'fg'}).string\n",
    "            away_fga = away_stats.find('td', attrs = {'data-stat': 'fga'}).string\n",
    "            away_fg_pct = away_stats.find('td', attrs = {'data-stat': 'fg_pct'}).string\n",
    "            away_fg3 = away_stats.find('td', attrs = {'data-stat': 'fg3'}).string\n",
    "            away_fg3a = away_stats.find('td', attrs = {'data-stat': 'fg3a'}).string\n",
    "            away_fg3_pct = away_stats.find('td', attrs = {'data-stat': 'fg3_pct'}).string\n",
    "            away_ft = away_stats.find('td', attrs = {'data-stat': 'ft'}).string\n",
    "            away_fta = away_stats.find('td', attrs = {'data-stat': 'fta'}).string\n",
    "            away_ft_pct = away_stats.find('td', attrs = {'data-stat': 'ft_pct'}).string\n",
    "            away_orb = away_stats.find('td', attrs = {'data-stat': 'orb'}).string\n",
    "            away_drb = away_stats.find('td', attrs = {'data-stat': 'drb'}).string\n",
    "            away_trb = away_stats.find('td', attrs = {'data-stat': 'trb'}).string\n",
    "            away_ast = away_stats.find('td', attrs = {'data-stat': 'ast'}).string\n",
    "            away_stl = away_stats.find('td', attrs = {'data-stat': 'stl'}).string\n",
    "            away_blk = away_stats.find('td', attrs = {'data-stat': 'blk'}).string\n",
    "            away_tov = away_stats.find('td', attrs = {'data-stat': 'tov'}).string\n",
    "            away_pf = away_stats.find('td', attrs = {'data-stat': 'pf'}).string\n",
    "            away_pts = away_stats.find('td', attrs = {'data-stat': 'pts'}).string\n",
    "\n",
    "            this_game_stats = pd.DataFrame({\n",
    "            \"date\": [game[\"date\"]],\n",
    "            \"home_team\":[home_team_id],\n",
    "            \"home_fg\":[home_fg],\n",
    "            \"home_fga\":[home_fga],\n",
    "            \"home_fg_pct\":[home_fg_pct],\n",
    "            \"home_fg3\":[home_fg3],\n",
    "            \"home_fg3a\":[home_fg3a],\n",
    "            \"home_fg3_pct\":[home_fg3_pct],\n",
    "            \"home_ft\":[home_ft],\n",
    "            \"home_fta\":[home_fta],\n",
    "            \"home_ft_pct\":[home_ft_pct],\n",
    "            \"home_orb\":[home_orb],\n",
    "            \"home_drb\":[home_drb],\n",
    "            \"home_trb\":[home_trb],\n",
    "            \"home_ast\":[home_ast],\n",
    "            \"home_stl\":[home_stl],\n",
    "            \"home_blk\":[home_blk],\n",
    "            \"home_tov\":[home_tov],\n",
    "            \"home_pf\":[home_pf],\n",
    "            \"home_pts\":[home_pts],\n",
    "            \"away_team\":[away_team_id],\n",
    "            \"away_fg\":[away_fg],\n",
    "            \"away_fga\":[away_fga],\n",
    "            \"away_fg_pct\":[away_fg_pct],\n",
    "            \"away_fg3\":[away_fg3],\n",
    "            \"away_fg3a\":[away_fg3a],\n",
    "            \"away_fg3_pct\":[away_fg3_pct],\n",
    "            \"away_ft\":[away_ft],\n",
    "            \"away_fta\":[away_fta],\n",
    "            \"away_ft_pct\":[away_ft_pct],\n",
    "            \"away_orb\":[away_orb],\n",
    "            \"away_drb\":[away_drb],\n",
    "            \"away_trb\":[away_trb],\n",
    "            \"away_ast\":[away_ast],\n",
    "            \"away_stl\":[away_stl],\n",
    "            \"away_blk\":[away_blk],\n",
    "            \"away_tov\":[away_tov],\n",
    "            \"away_pf\":[away_pf],\n",
    "            \"away_pts\":[away_pts],\n",
    "            \"arena\": [arena]})\n",
    "            \n",
    "            game_stats = pd.concat([game_stats, this_game_stats], ignore_index = True)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            error_new = pd.DataFrame({\"season\": game[\"season\"],\n",
    "            \"date\": game[\"date\"],\n",
    "            \"away_team_id\": away_team_id,\n",
    "            \"home_team_id\": home_team_id,\n",
    "            \"arena\": arena,\n",
    "            \"link\": ext,\n",
    "            \"error\": [\"error scraping table\"]})\n",
    "            flag = 1\n",
    "            try:\n",
    "                errors = pd.concat([errors, error_new], ignore_index = True)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                errors = error_new\n",
    "            continue\n",
    "\n",
    "    if flag == 1:\n",
    "        errors.to_csv(f\"{filename}_error.csv\")\n",
    "        print(\"errors: \", len(errors))\n",
    "    game_stats.to_csv(filename+\"game_stats.csv\")\n",
    "    return game_stats\n",
    "\n",
    "def game_stats_u():\n",
    "    \"\"\"\n",
    "    gets individual game statistics given a seasons games as a pandas df\n",
    "    \"\"\"\n",
    "    count = 1\n",
    "    flag = 0\n",
    "    season_schedule= pd.read_csv('season_schedules.csv')[['date', 'away_team_id', 'home_team_id', 'arena']]\n",
    "    game_stats = pd.read_csv('combined_game_stats.csv').drop(columns=['Unnamed: 0'])[['date', 'home_team', 'away_team', 'arena']]\n",
    "    \n",
    "    # Filter rows that are in season_schedule but not in game_stats\n",
    "    merged_df = pd.merge(season_schedule, game_stats, left_on=['date', 'away_team_id', 'home_team_id', 'arena'],\n",
    "                         right_on=['date', 'away_team', 'home_team', 'arena'], how='left', indicator=True)\n",
    "    \n",
    "    # Filter rows that are in season_schedule but not in game_stats\n",
    "    missing_rows = merged_df[merged_df['_merge'] == 'left_only'][season_schedule.columns]\n",
    "    \n",
    "    # merge season_schedule= pd.read_csv('season_schedules.csv') missing_rows\n",
    "    \n",
    "    # Show the missing rows\n",
    "    season_schedule= pd.read_csv('season_schedules.csv')\n",
    "    merged_missing_rows = pd.merge(missing_rows, season_schedule, on=['date', 'away_team_id', 'home_team_id', 'arena'], how='left')\n",
    "    game_stats = pd.DataFrame(columns = [\"date\",\n",
    "            \"home_team\",\n",
    "            \"home_fg\",\n",
    "            \"home_fga\",\n",
    "            \"home_fg_pct\",\n",
    "            \"home_fg3\",\n",
    "            \"home_fg3a\",\n",
    "            \"home_fg3_pct\",\n",
    "            \"home_ft\",\n",
    "            \"home_fta\",\n",
    "            \"home_ft_pct\",\n",
    "            \"home_orb\",\n",
    "            \"home_drb\",\n",
    "            \"home_trb\",\n",
    "            \"home_ast\",\n",
    "            \"home_stl\",\n",
    "            \"home_blk\",\n",
    "            \"home_tov\",\n",
    "            \"home_pf\",\n",
    "            \"home_pts\",\n",
    "            \"away_team\",\n",
    "            \"away_fg\",\n",
    "            \"away_fga\",\n",
    "            \"away_fg_pct\",\n",
    "            \"away_fg3\",\n",
    "            \"away_fg3a\",\n",
    "            \"away_fg3_pct\",\n",
    "            \"away_ft\",\n",
    "            \"away_fta\",\n",
    "            \"away_ft_pct\",\n",
    "            \"away_orb\",\n",
    "            \"away_drb\",\n",
    "            \"away_trb\",\n",
    "            \"away_ast\",\n",
    "            \"away_stl\",\n",
    "            \"away_blk\",\n",
    "            \"away_tov\",\n",
    "            \"away_pf\",\n",
    "            \"away_pts\",\n",
    "            \"arena\"])\n",
    "    \n",
    "    print(\"getitng individual game stats\", end = \" \")\n",
    "\n",
    "    for game in merged_missing_rows.iterrows():\n",
    "        print('.', end=\"\")\n",
    "        game = game[1]\n",
    "        home_team_id = game[\"home_team_id\"]\n",
    "        away_team_id = game[\"away_team_id\"]\n",
    "        arena = game[\"arena\"]\n",
    "        ext = game[\"link\"]\n",
    "        this_season = game[\"season\"]\n",
    "        try:\n",
    "            box_score_url = f\"https://www.basketball-reference.com{ext}\"\n",
    "            time.sleep(random.randint(5, 10))\n",
    "            open_link = urlopen(box_score_url)\n",
    "            soup = BeautifulSoup(open_link, features=\"lxml\")\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            error_new = pd.DataFrame({\"season\": game[\"season\"],\n",
    "            \"date\": game[\"date\"],\n",
    "            \"away_team_id\": away_team_id,\n",
    "            \"home_team_id\": home_team_id,\n",
    "            \"arena\": arena,\n",
    "            \"link\": ext,\n",
    "            \"error\": [\"404: invalid game link\"]})\n",
    "            try:\n",
    "                errors = pd.concat([errors, error_new], ignore_index = True)\n",
    "            except:\n",
    "                errors = error_new\n",
    "            continue\n",
    "        try:\n",
    "            home_stats = soup.find('table', attrs={'id':f\"box-{home_team_id}-game-basic\"}).tfoot.tr\n",
    "            home_fg = home_stats.find('td', attrs = {'data-stat': 'fg'}).string\n",
    "            home_fga = home_stats.find('td', attrs = {'data-stat': 'fga'}).string\n",
    "            home_fg_pct = home_stats.find('td', attrs = {'data-stat': 'fg_pct'}).string\n",
    "            home_fg3 = home_stats.find('td', attrs = {'data-stat': 'fg3'}).string\n",
    "            home_fg3a = home_stats.find('td', attrs = {'data-stat': 'fg3a'}).string\n",
    "            home_fg3_pct = home_stats.find('td', attrs = {'data-stat': 'fg3_pct'}).string\n",
    "            home_ft = home_stats.find('td', attrs = {'data-stat': 'ft'}).string\n",
    "            home_fta = home_stats.find('td', attrs = {'data-stat': 'fta'}).string\n",
    "            home_ft_pct = home_stats.find('td', attrs = {'data-stat': 'ft_pct'}).string\n",
    "            home_orb = home_stats.find('td', attrs = {'data-stat': 'orb'}).string\n",
    "            home_drb = home_stats.find('td', attrs = {'data-stat': 'drb'}).string\n",
    "            home_trb = home_stats.find('td', attrs = {'data-stat': 'trb'}).string\n",
    "            home_ast = home_stats.find('td', attrs = {'data-stat': 'ast'}).string\n",
    "            home_stl = home_stats.find('td', attrs = {'data-stat': 'stl'}).string\n",
    "            home_blk = home_stats.find('td', attrs = {'data-stat': 'blk'}).string\n",
    "            home_tov = home_stats.find('td', attrs = {'data-stat': 'tov'}).string\n",
    "            home_pf = home_stats.find('td', attrs = {'data-stat': 'pf'}).string\n",
    "            home_pts = home_stats.find('td', attrs = {'data-stat': 'pts'}).string\n",
    "\n",
    "            away_stats = soup.find('table', attrs={'id':f\"box-{away_team_id}-game-basic\"}).tfoot.tr\n",
    "            away_fg = away_stats.find('td', attrs = {'data-stat': 'fg'}).string\n",
    "            away_fga = away_stats.find('td', attrs = {'data-stat': 'fga'}).string\n",
    "            away_fg_pct = away_stats.find('td', attrs = {'data-stat': 'fg_pct'}).string\n",
    "            away_fg3 = away_stats.find('td', attrs = {'data-stat': 'fg3'}).string\n",
    "            away_fg3a = away_stats.find('td', attrs = {'data-stat': 'fg3a'}).string\n",
    "            away_fg3_pct = away_stats.find('td', attrs = {'data-stat': 'fg3_pct'}).string\n",
    "            away_ft = away_stats.find('td', attrs = {'data-stat': 'ft'}).string\n",
    "            away_fta = away_stats.find('td', attrs = {'data-stat': 'fta'}).string\n",
    "            away_ft_pct = away_stats.find('td', attrs = {'data-stat': 'ft_pct'}).string\n",
    "            away_orb = away_stats.find('td', attrs = {'data-stat': 'orb'}).string\n",
    "            away_drb = away_stats.find('td', attrs = {'data-stat': 'drb'}).string\n",
    "            away_trb = away_stats.find('td', attrs = {'data-stat': 'trb'}).string\n",
    "            away_ast = away_stats.find('td', attrs = {'data-stat': 'ast'}).string\n",
    "            away_stl = away_stats.find('td', attrs = {'data-stat': 'stl'}).string\n",
    "            away_blk = away_stats.find('td', attrs = {'data-stat': 'blk'}).string\n",
    "            away_tov = away_stats.find('td', attrs = {'data-stat': 'tov'}).string\n",
    "            away_pf = away_stats.find('td', attrs = {'data-stat': 'pf'}).string\n",
    "            away_pts = away_stats.find('td', attrs = {'data-stat': 'pts'}).string\n",
    "\n",
    "            this_game_stats = pd.DataFrame({\n",
    "            \"date\": [game[\"date\"]],\n",
    "            \"home_team\":[home_team_id],\n",
    "            \"home_fg\":[home_fg],\n",
    "            \"home_fga\":[home_fga],\n",
    "            \"home_fg_pct\":[home_fg_pct],\n",
    "            \"home_fg3\":[home_fg3],\n",
    "            \"home_fg3a\":[home_fg3a],\n",
    "            \"home_fg3_pct\":[home_fg3_pct],\n",
    "            \"home_ft\":[home_ft],\n",
    "            \"home_fta\":[home_fta],\n",
    "            \"home_ft_pct\":[home_ft_pct],\n",
    "            \"home_orb\":[home_orb],\n",
    "            \"home_drb\":[home_drb],\n",
    "            \"home_trb\":[home_trb],\n",
    "            \"home_ast\":[home_ast],\n",
    "            \"home_stl\":[home_stl],\n",
    "            \"home_blk\":[home_blk],\n",
    "            \"home_tov\":[home_tov],\n",
    "            \"home_pf\":[home_pf],\n",
    "            \"home_pts\":[home_pts],\n",
    "            \"away_team\":[away_team_id],\n",
    "            \"away_fg\":[away_fg],\n",
    "            \"away_fga\":[away_fga],\n",
    "            \"away_fg_pct\":[away_fg_pct],\n",
    "            \"away_fg3\":[away_fg3],\n",
    "            \"away_fg3a\":[away_fg3a],\n",
    "            \"away_fg3_pct\":[away_fg3_pct],\n",
    "            \"away_ft\":[away_ft],\n",
    "            \"away_fta\":[away_fta],\n",
    "            \"away_ft_pct\":[away_ft_pct],\n",
    "            \"away_orb\":[away_orb],\n",
    "            \"away_drb\":[away_drb],\n",
    "            \"away_trb\":[away_trb],\n",
    "            \"away_ast\":[away_ast],\n",
    "            \"away_stl\":[away_stl],\n",
    "            \"away_blk\":[away_blk],\n",
    "            \"away_tov\":[away_tov],\n",
    "            \"away_pf\":[away_pf],\n",
    "            \"away_pts\":[away_pts],\n",
    "            \"arena\": [arena]})\n",
    "            \n",
    "            game_stats = pd.concat([game_stats, this_game_stats], ignore_index = True)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            error_new = pd.DataFrame({\"season\": game[\"season\"],\n",
    "            \"date\": game[\"date\"],\n",
    "            \"away_team_id\": away_team_id,\n",
    "            \"home_team_id\": home_team_id,\n",
    "            \"arena\": arena,\n",
    "            \"link\": ext,\n",
    "            \"error\": [\"error scraping table\"]})\n",
    "            flag = 1\n",
    "            try:\n",
    "                errors = pd.concat([errors, error_new], ignore_index = True)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                errors = error_new\n",
    "            continue\n",
    "\n",
    "    if flag == 1:\n",
    "        print(\"errors: \", errors)\n",
    "    game_stats.to_csv(\"combined_game_stats.csv\")\n",
    "    return game_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "111a7dc4-cdc1-4bc7-bf19-a370e5a9d56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# years = [2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024]\n",
    "# seasons = team_roster_base(years = [2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024])\n",
    "# season_rosters =  get_rosters(seasons)\n",
    "# season_rosters = season_rosters[[\"Year\",\"Team\",\"team_dir\",\"Player\", \"player_dir\"]]\n",
    "# season_rosters.to_csv(\"season_rosters.csv\")\n",
    "# player_ERs= get_pers(season_rosters, \"Player_ERs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed343d56-c1fa-46a3-b352-d7209810edeb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#data integrity check- missing players \n",
    "season_rosters_players = season_rosters.drop_duplicates(subset = [\"player_dir\"], keep = \"first\")\n",
    "all_nba_players = season_rosters_players[\"player_dir\"] \n",
    "\n",
    "all_player_ERs_players = player_ERs.drop_duplicates(subset = [\"player_dir\"], keep = \"first\")[\"player_dir\"]\n",
    "#players missing \n",
    "all_missing_players = set(all_nba_players).difference(set(all_player_ERs_players))\n",
    "all_missing_players = season_rosters_players[season_rosters_players[\"player_dir\"].isin(all_missing_players)]\n",
    "\n",
    "missing_players_df = get_pers(all_missing_players, \"missing_players\")\n",
    "all_player_ERs_players = pd.concat([all_player_ERs_players, missing_players_df], ignore_index = True)\n",
    "\n",
    "#still missing players- likely have no stats/rookies\n",
    "mp = missing_players_df.drop_duplicates(subset = [\"player_dir\"], keep = \"first\")\n",
    "players_mp = mp[\"player_dir\"]\n",
    "all_player_ERs_players = pd.concat([all_player_ERs_players, players_mp], ignore_index = True)\n",
    "still_missing = set(all_nba_players).difference(set(all_player_ERs_players))\n",
    "\n",
    "if len(still_missing)>0:\n",
    "    print(len(still_missing),\" missing players\")\n",
    "    print(still_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe069bd1-934d-4474-a02b-6ba57ca865bd",
   "metadata": {},
   "source": [
    "manually add stats if needed:\n",
    "\n",
    "ex. \n",
    "\n",
    "luca_vildoza = pd.DataFrame({ \"season\": [2021-22],\n",
    "                                         \"team_id\": [\"MIL\"], \n",
    "                                         \"player_dir\": [\"/players/v/vildolu01.html\"], \n",
    "                                         \"per\":[17.9]})\n",
    "\n",
    "all_player_ERs_players = pd.concat([all_player_ERs_players, luca_vildoza], , ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65122645-27e1-491e-b49e-4e39a694fe31",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_player_ERs_players = all_player_ERs_players[all_player_ERs_players[\"season\"].isin([\"2014-15\", \"2015-16\", \"2016-17\", \"2017-18\", \"2018-19\", \"2019-20\", \"2020-21\", \"2021-22\",  \"2022-23\",  \"2023-24\"])]\n",
    "#this list is larger because of trades/transfers etc\n",
    "all_player_ERs_players.to_csv(\"player_ERs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0baa8b-1c09-40ba-9f9b-ec7d25a49cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "season_schedules = get_season_schedule(str(years), years)\n",
    "get_game_stats(season_schedules, \"combined_game_stats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "65861ec3-ba0b-4fdb-b73c-1fec7819a81a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def update_data(): \n",
    "    team_roster_base_u()\n",
    "    get_rosters_u()\n",
    "    get_pers_u()\n",
    "    season_rosters = pd.read_csv(\"season_rosters.csv\")[[\"Year\",\"Team\",\"team_dir\",\"Player\", \"player_dir\"]]\n",
    "    season_rosters['team_id'] = season_rosters['team_dir'].str.extract(r'/teams/(\\w{3})/')\n",
    "    pers = pd.read_csv(\"player_ERs.csv\")\n",
    "    pers['Year'] = pers['season']\n",
    "    pers['Year'] = pers['Year'].str[:2] + pers['Year'].str[-2:]\n",
    "    pers['Year'] = pers['Year'].astype('int64')\n",
    "    roster_pERs = season_rosters.merge(pers, how = \"right\", on=[\"Year\", \"player_dir\", \"team_id\"])[['Year', 'Team', 'team_dir', 'Player', 'player_dir', 'team_id', 'season', 'per']]\n",
    "    roster_pERs.to_csv(\"all_roster_pERs.csv\")\n",
    "    season_schedule_u()\n",
    "    # season game stats\n",
    "    season_schedules = pd.read_csv('season_schedules.csv')[['season', 'date', 'away_team_id', 'home_team_id', 'arena', 'link']]\n",
    "    game_stats_u()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
