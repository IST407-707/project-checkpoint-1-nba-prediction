{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4815cef-49a8-4304-84c6-b05d6ebf3994",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import pickle\n",
    "import lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f600286-2c99-4a68-b90b-ad68ff1573f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>month</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>november</td>\n",
       "      <td>invalid season link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023</td>\n",
       "      <td>january</td>\n",
       "      <td>invalid season link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023</td>\n",
       "      <td>march</td>\n",
       "      <td>invalid season link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024</td>\n",
       "      <td>april</td>\n",
       "      <td>unable to scrape table</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   season     month                   error\n",
       "0    2023  november     invalid season link\n",
       "1    2023   january     invalid season link\n",
       "2    2023     march     invalid season link\n",
       "3    2024     april  unable to scrape table"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get this data \n",
    "pd.read_parquet(\"[2022, 2023, 2024]_error.parquet.gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40d6a4a9-a6f9-4849-bea7-324c884b0b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_parquet(\"[2022, 2023, 2024]_game_stats.parquet.gzip\").to_csv(\"[2022, 2023, 2024]_game_stats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bfd26c56-6527-491c-bc4e-d0d6a01fe34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_season_schedule(filename, seasons = [2015]):\n",
    "    '''\n",
    "    Gets the season schedule (games played throughout the season) up until the playoffs.\n",
    "    creates a dataframe to inform us of any potential errors and allows code to not break because of errors\n",
    "    '''\n",
    "    season_schedule_table = pd.DataFrame(columns = [\"season\", \"date\", \"away_team_id\", \"home_team_id\", \"arena\", \"link\"])\n",
    "    # months = [\"november\", \"january\", \"march\"]\n",
    "    months = [\"april\"]\n",
    "    # [\"october\", \"november\", \"december\", \"january\", \"february\", \"march\", \"april\"]\n",
    "    \n",
    "    for year in seasons:\n",
    "        print(f\"getting {year} data....\")\n",
    "        for month in months:\n",
    "            month_schedule = f\"https://www.basketball-reference.com/leagues/NBA_{year}_games-{month}.html\"\n",
    "            print(month_schedule)\n",
    "            time.sleep(random.randint(2, 6))\n",
    "            #checks whether the link is valid and lets us know if any connections didnt work by saving to erros df. some errors here are good!\n",
    "            try:\n",
    "                month_schedule_link = urlopen(month_schedule)\n",
    "                soup = BeautifulSoup(month_schedule_link, features=\"lxml\")\n",
    "            except:\n",
    "                #the month may not have been a part of the season/year so each year will have some error months. this is really here for the covid seasons and high level error checking\n",
    "                errors = pd.DataFrame({\"season\": [year], \"month\":[month], \"error\": [\"invalid season link\"]})\n",
    "                try:\n",
    "                    name_of_file = f\"{filename}_error.csv\"\n",
    "                    errors = pd.concat([pd.read_parquet(name_of_file), errors], ignore_index = True)\n",
    "                    errors.to_parquet(name_of_file)\n",
    "                except:\n",
    "                    name_of_file = f\"{filename}_error.csv\"\n",
    "                    errors.to_parquet(name_of_file)\n",
    "                continue\n",
    "            try:\n",
    "                schedule_table = soup.find('table', attrs={'id':'schedule'})\n",
    "                games = schedule_table.tbody.findAll(\"tr\")\n",
    "                season = []\n",
    "                dates = []\n",
    "                away_team_ids = []\n",
    "                home_team_ids = []\n",
    "                arenas = []\n",
    "                links = []\n",
    "                for game in games:\n",
    "                #avoinding playoffs schedule\n",
    "                    if game.th.string == \"Playoffs\":\n",
    "                        break\n",
    "                    season.append(year)\n",
    "                    other_stats = game.findAll(\"td\")\n",
    "                    date = game.th.a.string\n",
    "                    dates.append(date)\n",
    "                    away_team = other_stats[1].a.get('href')[7:10]\n",
    "                    away_team_ids.append(away_team)\n",
    "                    home_team = other_stats[3].a.get('href')[7:10]\n",
    "                    home_team_ids.append(home_team)\n",
    "                    boxscore = other_stats[5].a.get('href')\n",
    "                    links.append(boxscore)\n",
    "                    arena = other_stats[8].string\n",
    "                    arenas.append(arena)\n",
    "                season_month = pd.DataFrame({\"season\": season,\n",
    "                                             \"date\": dates,\n",
    "                                             \"away_team_id\": away_team_ids,\n",
    "                                             \"home_team_id\": home_team_ids,\n",
    "                                              \"arena\":arenas,\n",
    "                                             \"link\":links\n",
    "                                            })\n",
    "            except:\n",
    "                #table error most likely 2020 april, where games werent played\n",
    "                errors = pd.DataFrame({\"season\": [year], \"month\":[month], \"error\": [\"unable to scrape table\"]})\n",
    "                try:\n",
    "                    name_of_file = f\"{filename}_error.csv\"\n",
    "                    errors = pd.concat([pd.read_parquet(name_of_file), errors], ignore_index = True)\n",
    "                    errors.to_parquet(name_of_file)\n",
    "                except:\n",
    "                    name_of_file = f\"{filename}_error.csv\"\n",
    "                    errors.to_parquet(name_of_file)\n",
    "                continue\n",
    "            # try to append to an existing file, if not exist create it\n",
    "            try:\n",
    "                name_of_file = f\"{filename}\"\n",
    "                season_games = pd.concat([pd.read_csv(name_of_file), season_month], ignore_index = True)\n",
    "                season_games.to_csv(name_of_file)\n",
    "            except:\n",
    "                name_of_file = f\"{filename}\"\n",
    "                season_month.to_csv(name_of_file)\n",
    "            print(month, \"completed\")\n",
    "    return pd.read_parquet(name_of_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8f6f29c7-42d4-4e13-b3fd-380fb56310ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_game_stats(dataframe, filename):\n",
    "    \"\"\"\n",
    "    gets individual game statistics given a seasons games as a pandas df\n",
    "    \"\"\"\n",
    "    count = 1\n",
    "    flag = 0\n",
    "\n",
    "    game_stats = pd.DataFrame(columns = [\"date\",\n",
    "            \"home_team\",\n",
    "            \"home_fg\",\n",
    "            \"home_fga\",\n",
    "            \"home_fg_pct\",\n",
    "            \"home_fg3\",\n",
    "            \"home_fg3a\",\n",
    "            \"home_fg3_pct\",\n",
    "            \"home_ft\",\n",
    "            \"home_fta\",\n",
    "            \"home_ft_pct\",\n",
    "            \"home_orb\",\n",
    "            \"home_drb\",\n",
    "            \"home_trb\",\n",
    "            \"home_ast\",\n",
    "            \"home_stl\",\n",
    "            \"home_blk\",\n",
    "            \"home_tov\",\n",
    "            \"home_pf\",\n",
    "            \"home_pts\",\n",
    "            \"away_team\",\n",
    "            \"away_fg\",\n",
    "            \"away_fga\",\n",
    "            \"away_fg_pct\",\n",
    "            \"away_fg3\",\n",
    "            \"away_fg3a\",\n",
    "            \"away_fg3_pct\",\n",
    "            \"away_ft\",\n",
    "            \"away_fta\",\n",
    "            \"away_ft_pct\",\n",
    "            \"away_orb\",\n",
    "            \"away_drb\",\n",
    "            \"away_trb\",\n",
    "            \"away_ast\",\n",
    "            \"away_stl\",\n",
    "            \"away_blk\",\n",
    "            \"away_tov\",\n",
    "            \"away_pf\",\n",
    "            \"away_pts\",\n",
    "            \"arena\"])\n",
    "    \n",
    "    print(\"getitng individual game stats\", end = \" \")\n",
    "\n",
    "    for game in dataframe.iterrows():\n",
    "        print('.', end=\"\")\n",
    "        game = game[1]\n",
    "        home_team_id = game[\"home_team_id\"]\n",
    "        away_team_id = game[\"away_team_id\"]\n",
    "        arena = game[\"arena\"]\n",
    "        ext = game[\"link\"]\n",
    "        this_season = game[\"season\"]\n",
    "        try:\n",
    "            box_score_url = f\"https://www.basketball-reference.com{ext}\"\n",
    "            time.sleep(random.randint(5, 10))\n",
    "            open_link = urlopen(box_score_url)\n",
    "            soup = BeautifulSoup(open_link, features=\"lxml\")\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            error = pd.DataFrame({\"season\": game[\"season\"],\n",
    "            \"date\": game[\"date\"],\n",
    "            \"away_team_id\": away_team_id,\n",
    "            \"home_team_id\": home_team_id,\n",
    "            \"arena\": arena,\n",
    "            \"link\": ext,\n",
    "            \"error\": [\"404: invalid game link\"]})\n",
    "            try:\n",
    "                name_of_file = f\"{filename}_error.csv\"\n",
    "                errors = pd.concat([pd.read_parquet(name_of_file), error], ignore_index = True)\n",
    "                errors.to_csv(name_of_file)\n",
    "            except:\n",
    "                name_of_file = f\"{filename}_error.csv\"\n",
    "                error.to_csv(name_of_file)\n",
    "            continue\n",
    "        try:\n",
    "            home_stats = soup.find('table', attrs={'id':f\"box-{home_team_id}-game-basic\"}).tfoot.tr\n",
    "            home_fg = home_stats.find('td', attrs = {'data-stat': 'fg'}).string\n",
    "            home_fga = home_stats.find('td', attrs = {'data-stat': 'fga'}).string\n",
    "            home_fg_pct = home_stats.find('td', attrs = {'data-stat': 'fg_pct'}).string\n",
    "            home_fg3 = home_stats.find('td', attrs = {'data-stat': 'fg3'}).string\n",
    "            home_fg3a = home_stats.find('td', attrs = {'data-stat': 'fg3a'}).string\n",
    "            home_fg3_pct = home_stats.find('td', attrs = {'data-stat': 'fg3_pct'}).string\n",
    "            home_ft = home_stats.find('td', attrs = {'data-stat': 'ft'}).string\n",
    "            home_fta = home_stats.find('td', attrs = {'data-stat': 'fta'}).string\n",
    "            home_ft_pct = home_stats.find('td', attrs = {'data-stat': 'ft_pct'}).string\n",
    "            home_orb = home_stats.find('td', attrs = {'data-stat': 'orb'}).string\n",
    "            home_drb = home_stats.find('td', attrs = {'data-stat': 'drb'}).string\n",
    "            home_trb = home_stats.find('td', attrs = {'data-stat': 'trb'}).string\n",
    "            home_ast = home_stats.find('td', attrs = {'data-stat': 'ast'}).string\n",
    "            home_stl = home_stats.find('td', attrs = {'data-stat': 'stl'}).string\n",
    "            home_blk = home_stats.find('td', attrs = {'data-stat': 'blk'}).string\n",
    "            home_tov = home_stats.find('td', attrs = {'data-stat': 'tov'}).string\n",
    "            home_pf = home_stats.find('td', attrs = {'data-stat': 'pf'}).string\n",
    "            home_pts = home_stats.find('td', attrs = {'data-stat': 'pts'}).string\n",
    "\n",
    "            away_stats = soup.find('table', attrs={'id':f\"box-{away_team_id}-game-basic\"}).tfoot.tr\n",
    "            away_fg = away_stats.find('td', attrs = {'data-stat': 'fg'}).string\n",
    "            away_fga = away_stats.find('td', attrs = {'data-stat': 'fga'}).string\n",
    "            away_fg_pct = away_stats.find('td', attrs = {'data-stat': 'fg_pct'}).string\n",
    "            away_fg3 = away_stats.find('td', attrs = {'data-stat': 'fg3'}).string\n",
    "            away_fg3a = away_stats.find('td', attrs = {'data-stat': 'fg3a'}).string\n",
    "            away_fg3_pct = away_stats.find('td', attrs = {'data-stat': 'fg3_pct'}).string\n",
    "            away_ft = away_stats.find('td', attrs = {'data-stat': 'ft'}).string\n",
    "            away_fta = away_stats.find('td', attrs = {'data-stat': 'fta'}).string\n",
    "            away_ft_pct = away_stats.find('td', attrs = {'data-stat': 'ft_pct'}).string\n",
    "            away_orb = away_stats.find('td', attrs = {'data-stat': 'orb'}).string\n",
    "            away_drb = away_stats.find('td', attrs = {'data-stat': 'drb'}).string\n",
    "            away_trb = away_stats.find('td', attrs = {'data-stat': 'trb'}).string\n",
    "            away_ast = away_stats.find('td', attrs = {'data-stat': 'ast'}).string\n",
    "            away_stl = away_stats.find('td', attrs = {'data-stat': 'stl'}).string\n",
    "            away_blk = away_stats.find('td', attrs = {'data-stat': 'blk'}).string\n",
    "            away_tov = away_stats.find('td', attrs = {'data-stat': 'tov'}).string\n",
    "            away_pf = away_stats.find('td', attrs = {'data-stat': 'pf'}).string\n",
    "            away_pts = away_stats.find('td', attrs = {'data-stat': 'pts'}).string\n",
    "\n",
    "            this_game_stats = pd.DataFrame({\n",
    "            \"date\": [game[\"date\"]],\n",
    "            \"home_team\":[home_team_id],\n",
    "            \"home_fg\":[home_fg],\n",
    "            \"home_fga\":[home_fga],\n",
    "            \"home_fg_pct\":[home_fg_pct],\n",
    "            \"home_fg3\":[home_fg3],\n",
    "            \"home_fg3a\":[home_fg3a],\n",
    "            \"home_fg3_pct\":[home_fg3_pct],\n",
    "            \"home_ft\":[home_ft],\n",
    "            \"home_fta\":[home_fta],\n",
    "            \"home_ft_pct\":[home_ft_pct],\n",
    "            \"home_orb\":[home_orb],\n",
    "            \"home_drb\":[home_drb],\n",
    "            \"home_trb\":[home_trb],\n",
    "            \"home_ast\":[home_ast],\n",
    "            \"home_stl\":[home_stl],\n",
    "            \"home_blk\":[home_blk],\n",
    "            \"home_tov\":[home_tov],\n",
    "            \"home_pf\":[home_pf],\n",
    "            \"home_pts\":[home_pts],\n",
    "            \"away_team\":[away_team_id],\n",
    "            \"away_fg\":[away_fg],\n",
    "            \"away_fga\":[away_fga],\n",
    "            \"away_fg_pct\":[away_fg_pct],\n",
    "            \"away_fg3\":[away_fg3],\n",
    "            \"away_fg3a\":[away_fg3a],\n",
    "            \"away_fg3_pct\":[away_fg3_pct],\n",
    "            \"away_ft\":[away_ft],\n",
    "            \"away_fta\":[away_fta],\n",
    "            \"away_ft_pct\":[away_ft_pct],\n",
    "            \"away_orb\":[away_orb],\n",
    "            \"away_drb\":[away_drb],\n",
    "            \"away_trb\":[away_trb],\n",
    "            \"away_ast\":[away_ast],\n",
    "            \"away_stl\":[away_stl],\n",
    "            \"away_blk\":[away_blk],\n",
    "            \"away_tov\":[away_tov],\n",
    "            \"away_pf\":[away_pf],\n",
    "            \"away_pts\":[away_pts],\n",
    "            \"arena\": [arena]})\n",
    "            \n",
    "            game_stats = pd.concat([game_stats, this_game_stats], ignore_index = True)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            error = pd.DataFrame({\"season\": game[\"season\"],\n",
    "            \"date\": game[\"date\"],\n",
    "            \"away_team_id\": away_team_id,\n",
    "            \"home_team_id\": home_team_id,\n",
    "            \"arena\": arena,\n",
    "            \"link\": ext,\n",
    "            \"error\": [\"error scraping table\"]})\n",
    "            flag = 1\n",
    "            try:\n",
    "                name_of_file = f\"{filename}_error.csv\"\n",
    "                errors = pd.concat([pd.read_parquet(name_of_file), error], ignore_index = True)\n",
    "                errors.to_csv(name_of_file)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                name_of_file = f\"{filename}_error.csv\"\n",
    "                error.to_csv(name_of_file)\n",
    "            continue\n",
    "\n",
    "\n",
    "    if count % 100 == 0:\n",
    "        name_of_file = f\"{filename}.csv\"\n",
    "        try:\n",
    "            existing_df = pd.read_csv(name_of_file)\n",
    "            combined_df = pd.concat([game_stats, existing_df], ignore_index = True)\n",
    "            combined_df.to_csv(name_of_file)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            game_stats.to_csv(name_of_file)\n",
    "       \n",
    "        scraped = len(pd.read_csv(name_of_file))\n",
    "        print(f\"\\nstats scraped from {scraped} of {len(dataframe)} in {this_season}\")\n",
    "        game_stats = pd.DataFrame(columns = game_stats.columns)\n",
    "\n",
    "        \n",
    "    if count == len(dataframe):\n",
    "        name_of_file = f\"{filename}.csv\"\n",
    "        existing_df = pd.read_csv(name_of_file)\n",
    "        combined_df = pd.concat([game_stats, existing_df], ignore_index = True)\n",
    "        combined_df.to_csv(name_of_file)\n",
    "    count+=1\n",
    "\n",
    "    if flag == 1:\n",
    "        print(\"errors: \", len(pd.read_csv(f\"{filename}_error.csv\")))\n",
    "    return game_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8a9ed1ce-a6d6-4357-906c-8c7ca324f96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting 2024 data....\n",
      "https://www.basketball-reference.com/leagues/NBA_2024_games-april.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>month</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024</td>\n",
       "      <td>april</td>\n",
       "      <td>unable to scrape table</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   season  month                   error\n",
       "0    2024  april  unable to scrape table"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_season_schedule(\"[2024]\", [2024])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e317ee-c4fe-4d74-97b5-c26c685210c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "882aaa96-c355-4315-8f53-de3cc78227de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getitng individual game stats ................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................."
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>home_team</th>\n",
       "      <th>home_fg</th>\n",
       "      <th>home_fga</th>\n",
       "      <th>home_fg_pct</th>\n",
       "      <th>home_fg3</th>\n",
       "      <th>home_fg3a</th>\n",
       "      <th>home_fg3_pct</th>\n",
       "      <th>home_ft</th>\n",
       "      <th>home_fta</th>\n",
       "      <th>...</th>\n",
       "      <th>away_orb</th>\n",
       "      <th>away_drb</th>\n",
       "      <th>away_trb</th>\n",
       "      <th>away_ast</th>\n",
       "      <th>away_stl</th>\n",
       "      <th>away_blk</th>\n",
       "      <th>away_tov</th>\n",
       "      <th>away_pf</th>\n",
       "      <th>away_pts</th>\n",
       "      <th>arena</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tue, Nov 1, 2022</td>\n",
       "      <td>BRK</td>\n",
       "      <td>36</td>\n",
       "      <td>74</td>\n",
       "      <td>.486</td>\n",
       "      <td>12</td>\n",
       "      <td>32</td>\n",
       "      <td>.375</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>33</td>\n",
       "      <td>44</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>108</td>\n",
       "      <td>Barclays Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tue, Nov 1, 2022</td>\n",
       "      <td>MIA</td>\n",
       "      <td>40</td>\n",
       "      <td>88</td>\n",
       "      <td>.455</td>\n",
       "      <td>16</td>\n",
       "      <td>42</td>\n",
       "      <td>.381</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "      <td>41</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>109</td>\n",
       "      <td>Kaseya Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tue, Nov 1, 2022</td>\n",
       "      <td>OKC</td>\n",
       "      <td>45</td>\n",
       "      <td>95</td>\n",
       "      <td>.474</td>\n",
       "      <td>10</td>\n",
       "      <td>34</td>\n",
       "      <td>.294</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>37</td>\n",
       "      <td>49</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>14</td>\n",
       "      <td>108</td>\n",
       "      <td>Paycom Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tue, Nov 1, 2022</td>\n",
       "      <td>PHO</td>\n",
       "      <td>41</td>\n",
       "      <td>89</td>\n",
       "      <td>.461</td>\n",
       "      <td>17</td>\n",
       "      <td>43</td>\n",
       "      <td>.395</td>\n",
       "      <td>17</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>32</td>\n",
       "      <td>42</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>24</td>\n",
       "      <td>107</td>\n",
       "      <td>Footprint Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wed, Nov 2, 2022</td>\n",
       "      <td>PHI</td>\n",
       "      <td>39</td>\n",
       "      <td>84</td>\n",
       "      <td>.464</td>\n",
       "      <td>19</td>\n",
       "      <td>36</td>\n",
       "      <td>.528</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>36</td>\n",
       "      <td>43</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>121</td>\n",
       "      <td>Wells Fargo Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>Fri, Mar 31, 2023</td>\n",
       "      <td>MEM</td>\n",
       "      <td>43</td>\n",
       "      <td>96</td>\n",
       "      <td>.448</td>\n",
       "      <td>9</td>\n",
       "      <td>33</td>\n",
       "      <td>.273</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>38</td>\n",
       "      <td>50</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>94</td>\n",
       "      <td>FedEx Forum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>Fri, Mar 31, 2023</td>\n",
       "      <td>MIN</td>\n",
       "      <td>41</td>\n",
       "      <td>95</td>\n",
       "      <td>.432</td>\n",
       "      <td>13</td>\n",
       "      <td>39</td>\n",
       "      <td>.333</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>38</td>\n",
       "      <td>53</td>\n",
       "      <td>28</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>123</td>\n",
       "      <td>Target Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>Fri, Mar 31, 2023</td>\n",
       "      <td>GSW</td>\n",
       "      <td>47</td>\n",
       "      <td>93</td>\n",
       "      <td>.505</td>\n",
       "      <td>21</td>\n",
       "      <td>49</td>\n",
       "      <td>.429</td>\n",
       "      <td>15</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>32</td>\n",
       "      <td>46</td>\n",
       "      <td>27</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>115</td>\n",
       "      <td>Chase Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>Fri, Mar 31, 2023</td>\n",
       "      <td>POR</td>\n",
       "      <td>40</td>\n",
       "      <td>85</td>\n",
       "      <td>.471</td>\n",
       "      <td>19</td>\n",
       "      <td>38</td>\n",
       "      <td>.500</td>\n",
       "      <td>15</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>41</td>\n",
       "      <td>38</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>138</td>\n",
       "      <td>Moda Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>Fri, Mar 31, 2023</td>\n",
       "      <td>PHO</td>\n",
       "      <td>37</td>\n",
       "      <td>88</td>\n",
       "      <td>.420</td>\n",
       "      <td>10</td>\n",
       "      <td>27</td>\n",
       "      <td>.370</td>\n",
       "      <td>16</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>36</td>\n",
       "      <td>51</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>93</td>\n",
       "      <td>Footprint Center</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>673 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date home_team home_fg home_fga home_fg_pct home_fg3  \\\n",
       "0     Tue, Nov 1, 2022       BRK      36       74        .486       12   \n",
       "1     Tue, Nov 1, 2022       MIA      40       88        .455       16   \n",
       "2     Tue, Nov 1, 2022       OKC      45       95        .474       10   \n",
       "3     Tue, Nov 1, 2022       PHO      41       89        .461       17   \n",
       "4     Wed, Nov 2, 2022       PHI      39       84        .464       19   \n",
       "..                 ...       ...     ...      ...         ...      ...   \n",
       "668  Fri, Mar 31, 2023       MEM      43       96        .448        9   \n",
       "669  Fri, Mar 31, 2023       MIN      41       95        .432       13   \n",
       "670  Fri, Mar 31, 2023       GSW      47       93        .505       21   \n",
       "671  Fri, Mar 31, 2023       POR      40       85        .471       19   \n",
       "672  Fri, Mar 31, 2023       PHO      37       88        .420       10   \n",
       "\n",
       "    home_fg3a home_fg3_pct home_ft home_fta  ... away_orb away_drb away_trb  \\\n",
       "0          32         .375      15       19  ...       11       33       44   \n",
       "1          42         .381      20       20  ...       10       31       41   \n",
       "2          34         .294      16       20  ...       12       37       49   \n",
       "3          43         .395      17       22  ...       10       32       42   \n",
       "4          36         .528      14       20  ...        7       36       43   \n",
       "..        ...          ...     ...      ...  ...      ...      ...      ...   \n",
       "668        33         .273      13       17  ...       12       38       50   \n",
       "669        39         .333      16       19  ...       15       38       53   \n",
       "670        49         .429      15       21  ...       14       32       46   \n",
       "671        38         .500      15       23  ...        8       33       41   \n",
       "672        27         .370      16       21  ...       15       36       51   \n",
       "\n",
       "    away_ast away_stl away_blk away_tov away_pf away_pts               arena  \n",
       "0         20        8        4        9      13      108     Barclays Center  \n",
       "1         31        8        5       20      22      109       Kaseya Center  \n",
       "2         20        7       10       24      14      108       Paycom Center  \n",
       "3         24        5        4       16      24      107    Footprint Center  \n",
       "4         27        4        9        7      18      121  Wells Fargo Center  \n",
       "..       ...      ...      ...      ...     ...      ...                 ...  \n",
       "668       26        5        8       17      14       94         FedEx Forum  \n",
       "669       28       10        5       16      17      123       Target Center  \n",
       "670       27        8        4       13      20      115        Chase Center  \n",
       "671       38       11        7       13      21      138         Moda Center  \n",
       "672       19       11        5       11      16       93    Footprint Center  \n",
       "\n",
       "[673 rows x 40 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schedule_2023 = pd.read_parquet(\"[2023].parquet.gzip\")\n",
    "get_game_stats(schedule_2023, \"missing_2023_gs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0e23c94a-1e53-4762-9fe8-4eb044b26dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_game_stats = _54\n",
    "scraped_game_stats.to_csv(\"[2022, 2023]_game_stats.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
