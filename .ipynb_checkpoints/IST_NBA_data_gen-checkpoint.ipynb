{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "O8XafXVLEEhL",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# required libraries\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-gVkW9J9JnD-"
   },
   "source": [
    "# create a function to scrape team performance for multiple years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qTNgHDmdl5eO"
   },
   "source": [
    "to get rosters\n",
    "\n",
    "start with the year -\n",
    "\n",
    "https://www.basketball-reference.com/leagues/NBA_YEAR_ratings\n",
    "\n",
    "loop through each team\n",
    "\n",
    "https://www.basketball-reference.com/teams/THIS_TEAM/2014.html\n",
    "\n",
    "get players from roster -\n",
    "note- no per per game so lets use per from previous season\n",
    "\n",
    "player column of roster\n",
    "which contains a link to the players profile\n",
    "https://www.basketball-reference.com/players/p/pendeje02.html\n",
    "\n",
    "<a href=\"/players/p/pendeje02.html\">Jeff Ayres</a>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2pXS2tHAgmXa",
    "outputId": "37860ceb-6834-41d6-b634-ed6e65572368",
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'year_team_link.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 58\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m yearly_rosters\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# seasons = team_roster_base(years = [2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022])\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m seasons \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43myear_team_link.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m team_rosters \u001b[38;5;241m=\u001b[39m get_rosters(seasons)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'year_team_link.csv'"
     ]
    }
   ],
   "source": [
    "def team_roster_base(years = [2015]):\n",
    "    team_roster_base = pd.DataFrame(columns = [\"Year\", \"Team\", \"team_dir\"])\n",
    "    # loop through each year\n",
    "    for y in years:\n",
    "        # NBA season to scrape- year is season end so 2015 is 2014-15 season \n",
    "        year = y\n",
    "        url = f\"https://www.basketball-reference.com/leagues/NBA_{year}_ratings.html\"\n",
    "        html = urlopen(url)\n",
    "        soup = BeautifulSoup(html, features=\"lxml\")\n",
    "        table = soup.find('table', attrs={'id':'ratings'})\n",
    "        teams = table.tbody.findAll(\"tr\")\n",
    "        for team in teams: #get team names and links - would get stats here as well\n",
    "            team_name= team.td.string\n",
    "            team_dir = team.td.a.get('href')\n",
    "            team_year={\"Year\": year, \"Team\": team_name, \"team_dir\": team_dir}\n",
    "            team_roster_base = team_roster_base.append(team_year, ignore_index = True)\n",
    "        time.sleep(5)\n",
    "    # export to csv\n",
    "    team_roster_base.to_csv(\"year_team_link.csv\", index=False)\n",
    "    return team_roster_base\n",
    "\n",
    "def get_rosters(team_roster_base):\n",
    "    save_int = 60\n",
    "    save = 0\n",
    "    yearly_rosters = pd.DataFrame(columns = [\"Year\", \"Team\", \"team_dir\", \"Player\", \"player_dir\"])\n",
    "    base_url = \"https://www.basketball-reference.com\"\n",
    "    for index, row in team_roster_base.iterrows():\n",
    "        roster_url = base_url+str(row['team_dir'])\n",
    "        time.sleep(random.randint(3, 9))\n",
    "        html_team = urlopen(roster_url)\n",
    "        soup = BeautifulSoup(html_team, features=\"lxml\")\n",
    "        roster_table = soup.find('table', attrs={'id':'roster'})\n",
    "        players = roster_table.tbody.findAll(\"tr\")\n",
    "        year = [str(row['Year'])]\n",
    "        team = [str(row['Team'])]\n",
    "        team_dir = [str(row['team_dir'])]\n",
    "        for player in players:\n",
    "            player_name = [str(player.td.string)]\n",
    "            player_dir = [str(player.td.a.get('href'))]\n",
    "            team_year_player = pd.DataFrame({\"Year\": year,\n",
    "                                             \"Team\": team, \n",
    "                                             \"team_dir\": team_dir, \n",
    "                                             \"Player\": player_name, \n",
    "                                             \"player_dir\": player_dir})\n",
    "            yearly_rosters = pd.concat([yearly_rosters, team_year_player], ignore_index = True)\n",
    "            save+=1\n",
    "        if save >= save_int:\n",
    "            save = 0\n",
    "            print(len(yearly_rosters))\n",
    "            with open(\"df.pickle\", \"wb\") as file:\n",
    "                pickle.dump(yearly_rosters, file)\n",
    "    with open(\"df.pickle\", \"wb\") as file:\n",
    "                pickle.dump(yearly_rosters, file)\n",
    "    yearly_rosters.to_csv(\"season_rosters.csv\", index=False)\n",
    "    return yearly_rosters\n",
    "\n",
    "# seasons = team_roster_base(years = [2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022])\n",
    "seasons = pd.read_csv(\"year_team_link.csv\")\n",
    "team_rosters = get_rosters(seasons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_pers(season_rosters, filename):\n",
    "    #get player efficiency ratings \n",
    "    progress = 0 \n",
    "    save = 0\n",
    "    per_table = pd.DataFrame(columns = [\"season\", \"team_id\", \"player_dir\", \"per\"])\n",
    "    save_int = 50   \n",
    "    players_list = []\n",
    "    for index, row in season_rosters.iterrows():\n",
    "        progress+= 1\n",
    "        season = str(int(row['Year'])-1)+'-'+row['Year'][2:]\n",
    "        team = row['team_dir'][7:10]\n",
    "        base_url = \"https://www.basketball-reference.com\"\n",
    "        player_url = base_url+str(row['player_dir'])\n",
    "        if row['player_dir'] in players_list:\n",
    "            continue\n",
    "        else:\n",
    "            players_list.append(row['player_dir'])\n",
    "        try:\n",
    "            time.sleep(random.randint(3, 9))\n",
    "            html_player = urlopen(player_url)\n",
    "            player_seasons = []\n",
    "            player_team_ids = []\n",
    "            # player_team_dirs = []\n",
    "            player_dirs = []\n",
    "            player_pers = []\n",
    "            soup = BeautifulSoup(html_player, features=\"lxml\")\n",
    "            adv_table = soup.find('table', attrs={'id':'advanced'})\n",
    "            teams = adv_table.tbody.findAll(\"tr\")\n",
    "            for team in teams:\n",
    "                # th is season td is all other stats \n",
    "                player_seasons.append(str(team.th.a.string))\n",
    "                print(player_seasons)\n",
    "                other_stats = team.findAll('td')\n",
    "                team_id = other_stats[1].string\n",
    "                player_team_ids.append(str(team_id))\n",
    "                # player_team_dirs.append(row['team_dir'])\n",
    "                player_dirs.append(row['player_dir'])\n",
    "                per_value = other_stats[6].string\n",
    "                player_pers.append(per_value)\n",
    "            this_player = pd .DataFrame({ \"season\": player_seasons,\n",
    "                                         \"team_id\": player_team_ids, \n",
    "                                         \"player_dir\": player_dirs, \n",
    "                                         \"per\":player_pers})\n",
    "            per_table = pd.concat([per_table, this_player], ignore_index = True)\n",
    "            save+=1\n",
    "        except:\n",
    "            print(row)\n",
    "        if save >= save_int:\n",
    "            save = 0\n",
    "            print(len(per_table), end = \" \")\n",
    "#changing filenames for second run \n",
    "            per_table.to_parquet(f'{filename}.parquet.gzip',\n",
    "              compression='gzip')\n",
    "    # https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_parquet.html\n",
    "    per_table.to_parquet(f'{filename}.parquet.gzip',\n",
    "              compression='gzip')\n",
    "        \n",
    "    # per_table.to_csv(\"PER_table.csv\", index=False)\n",
    "    return per_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1240"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# players on our rosters\n",
    "season_rosters = pd.read_pickle(\"df.pickle\", compression='infer')\n",
    "# pers = get_pers(season_rosters)\n",
    "season_rosters_players = season_rosters.drop_duplicates(subset = [\"player_dir\"], keep = \"first\")\n",
    "players_all = season_rosters_players[\"player_dir\"]\n",
    "len(players_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       /players/b/barbole01.html\n",
       "16      /players/b/barneha02.html\n",
       "30      /players/b/bogutan01.html\n",
       "46      /players/c/curryst01.html\n",
       "61      /players/e/ezelife01.html\n",
       "                  ...            \n",
       "8864    /players/b/brookar01.html\n",
       "8869     /players/l/lamban01.html\n",
       "8872    /players/m/martike04.html\n",
       "8878    /players/o/oliveca01.html\n",
       "8880     /players/t/tateja01.html\n",
       "Name: player_dir, Length: 1100, dtype: object"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#player pers every season up to the error\n",
    "season_PER = pd.read_parquet('PER_table.parquet.gzip') \n",
    "season_PER= season_PER.drop_duplicates(subset = [\"player_dir\"], keep = \"first\")\n",
    "players_have = season_PER[\"player_dir\"]\n",
    "players_have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#players missing due to the error\n",
    "players_needed = set(players_all).difference(set(players_have))\n",
    "len(set(players_all).difference(set(players_have)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Team</th>\n",
       "      <th>team_dir</th>\n",
       "      <th>Player</th>\n",
       "      <th>player_dir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4012</th>\n",
       "      <td>2021</td>\n",
       "      <td>Houston Rockets</td>\n",
       "      <td>/teams/HOU/2021.html</td>\n",
       "      <td>Brodric Thomas</td>\n",
       "      <td>/players/t/thomabr01.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4034</th>\n",
       "      <td>2021</td>\n",
       "      <td>Cleveland Cavaliers</td>\n",
       "      <td>/teams/CLE/2021.html</td>\n",
       "      <td>Isaac Okoro</td>\n",
       "      <td>/players/o/okorois01.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4038</th>\n",
       "      <td>2021</td>\n",
       "      <td>Cleveland Cavaliers</td>\n",
       "      <td>/teams/CLE/2021.html</td>\n",
       "      <td>Lamar Stevens</td>\n",
       "      <td>/players/s/stevela01.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4042</th>\n",
       "      <td>2021</td>\n",
       "      <td>Cleveland Cavaliers</td>\n",
       "      <td>/teams/CLE/2021.html</td>\n",
       "      <td>Dylan Windler</td>\n",
       "      <td>/players/w/windldy01.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4044</th>\n",
       "      <td>2021</td>\n",
       "      <td>Orlando Magic</td>\n",
       "      <td>/teams/ORL/2021.html</td>\n",
       "      <td>Cole Anthony</td>\n",
       "      <td>/players/a/anthoco01.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4783</th>\n",
       "      <td>2022</td>\n",
       "      <td>Portland Trail Blazers</td>\n",
       "      <td>/teams/POR/2022.html</td>\n",
       "      <td>Greg Brown III</td>\n",
       "      <td>/players/b/browngr01.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4785</th>\n",
       "      <td>2022</td>\n",
       "      <td>Portland Trail Blazers</td>\n",
       "      <td>/teams/POR/2022.html</td>\n",
       "      <td>Jarron Cumberland</td>\n",
       "      <td>/players/c/cumbeja01.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4796</th>\n",
       "      <td>2022</td>\n",
       "      <td>Portland Trail Blazers</td>\n",
       "      <td>/teams/POR/2022.html</td>\n",
       "      <td>Cameron McGriff</td>\n",
       "      <td>/players/m/mcgrica01.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4805</th>\n",
       "      <td>2022</td>\n",
       "      <td>Portland Trail Blazers</td>\n",
       "      <td>/teams/POR/2022.html</td>\n",
       "      <td>Trendon Watford</td>\n",
       "      <td>/players/w/watfotr01.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4806</th>\n",
       "      <td>2022</td>\n",
       "      <td>Portland Trail Blazers</td>\n",
       "      <td>/teams/POR/2022.html</td>\n",
       "      <td>Brandon Williams</td>\n",
       "      <td>/players/w/willibr03.html</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Year                    Team              team_dir             Player  \\\n",
       "4012  2021         Houston Rockets  /teams/HOU/2021.html     Brodric Thomas   \n",
       "4034  2021     Cleveland Cavaliers  /teams/CLE/2021.html        Isaac Okoro   \n",
       "4038  2021     Cleveland Cavaliers  /teams/CLE/2021.html      Lamar Stevens   \n",
       "4042  2021     Cleveland Cavaliers  /teams/CLE/2021.html      Dylan Windler   \n",
       "4044  2021           Orlando Magic  /teams/ORL/2021.html       Cole Anthony   \n",
       "...    ...                     ...                   ...                ...   \n",
       "4783  2022  Portland Trail Blazers  /teams/POR/2022.html     Greg Brown III   \n",
       "4785  2022  Portland Trail Blazers  /teams/POR/2022.html  Jarron Cumberland   \n",
       "4796  2022  Portland Trail Blazers  /teams/POR/2022.html    Cameron McGriff   \n",
       "4805  2022  Portland Trail Blazers  /teams/POR/2022.html    Trendon Watford   \n",
       "4806  2022  Portland Trail Blazers  /teams/POR/2022.html   Brandon Williams   \n",
       "\n",
       "                     player_dir  \n",
       "4012  /players/t/thomabr01.html  \n",
       "4034  /players/o/okorois01.html  \n",
       "4038  /players/s/stevela01.html  \n",
       "4042  /players/w/windldy01.html  \n",
       "4044  /players/a/anthoco01.html  \n",
       "...                         ...  \n",
       "4783  /players/b/browngr01.html  \n",
       "4785  /players/c/cumbeja01.html  \n",
       "4796  /players/m/mcgrica01.html  \n",
       "4805  /players/w/watfotr01.html  \n",
       "4806  /players/w/willibr03.html  \n",
       "\n",
       "[140 rows x 5 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#selecting the players we dont have \n",
    "missing_players = season_rosters_players[season_rosters_players[\"player_dir\"].isin(players_needed)]\n",
    "len(missing_players)\n",
    "missing_players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year                               2022\n",
      "Team                    Milwaukee Bucks\n",
      "team_dir           /teams/MIL/2022.html\n",
      "Player                     Luca Vildoza\n",
      "player_dir    /players/v/vildolu01.html\n",
      "Name: 4285, dtype: object\n",
      "151 276 "
     ]
    }
   ],
   "source": [
    "# scraping the missing players into missing pers\n",
    "missing_players_df = get_pers(missing_players, \"missing_players\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# players after scraping attempt for missing \n",
    "mp = pd.read_parquet('missing_players.parquet.gzip') \n",
    "mp= mp.drop_duplicates(subset = [\"player_dir\"], keep = \"first\")\n",
    "players_mp = mp[\"player_dir\"]\n",
    "players_mp\n",
    "#merge with existing\n",
    "players_have = pd.concat([players_have, players_mp], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#players still missing\n",
    "players_needed = set(players_all).difference(set(players_have))\n",
    "len(set(players_all).difference(set(players_have)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Team</th>\n",
       "      <th>team_dir</th>\n",
       "      <th>Player</th>\n",
       "      <th>player_dir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4285</th>\n",
       "      <td>2022</td>\n",
       "      <td>Milwaukee Bucks</td>\n",
       "      <td>/teams/MIL/2022.html</td>\n",
       "      <td>Luca Vildoza</td>\n",
       "      <td>/players/v/vildolu01.html</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Year             Team              team_dir        Player  \\\n",
       "4285  2022  Milwaukee Bucks  /teams/MIL/2022.html  Luca Vildoza   \n",
       "\n",
       "                     player_dir  \n",
       "4285  /players/v/vildolu01.html  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#selecting the player we dont have \n",
    "missing_players = season_rosters_players[season_rosters_players[\"player_dir\"].isin(players_needed)]\n",
    "len(missing_players)\n",
    "missing_players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>team_id</th>\n",
       "      <th>player_dir</th>\n",
       "      <th>per</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2014-15</td>\n",
       "      <td>GSW</td>\n",
       "      <td>/players/b/barbole01.html</td>\n",
       "      <td>15.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2015-16</td>\n",
       "      <td>GSW</td>\n",
       "      <td>/players/b/barbole01.html</td>\n",
       "      <td>11.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2016-17</td>\n",
       "      <td>PHO</td>\n",
       "      <td>/players/b/barbole01.html</td>\n",
       "      <td>11.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2014-15</td>\n",
       "      <td>GSW</td>\n",
       "      <td>/players/b/barneha02.html</td>\n",
       "      <td>13.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2015-16</td>\n",
       "      <td>GSW</td>\n",
       "      <td>/players/b/barneha02.html</td>\n",
       "      <td>12.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9245</th>\n",
       "      <td>2021-22</td>\n",
       "      <td>POR</td>\n",
       "      <td>/players/b/browngr01.html</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9248</th>\n",
       "      <td>2021-22</td>\n",
       "      <td>POR</td>\n",
       "      <td>/players/c/cumbeja01.html</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9249</th>\n",
       "      <td>2021-22</td>\n",
       "      <td>POR</td>\n",
       "      <td>/players/m/mcgrica01.html</td>\n",
       "      <td>12.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9250</th>\n",
       "      <td>2021-22</td>\n",
       "      <td>POR</td>\n",
       "      <td>/players/w/watfotr01.html</td>\n",
       "      <td>15.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9253</th>\n",
       "      <td>2021-22</td>\n",
       "      <td>POR</td>\n",
       "      <td>/players/w/willibr03.html</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5143 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       season team_id                 player_dir   per\n",
       "13    2014-15     GSW  /players/b/barbole01.html  15.3\n",
       "14    2015-16     GSW  /players/b/barbole01.html  11.7\n",
       "15    2016-17     PHO  /players/b/barbole01.html  11.5\n",
       "18    2014-15     GSW  /players/b/barneha02.html  13.4\n",
       "19    2015-16     GSW  /players/b/barneha02.html  12.3\n",
       "...       ...     ...                        ...   ...\n",
       "9245  2021-22     POR  /players/b/browngr01.html  11.0\n",
       "9248  2021-22     POR  /players/c/cumbeja01.html   8.4\n",
       "9249  2021-22     POR  /players/m/mcgrica01.html  12.5\n",
       "9250  2021-22     POR  /players/w/watfotr01.html  15.8\n",
       "9253  2021-22     POR  /players/w/willibr03.html  11.0\n",
       "\n",
       "[5143 rows x 4 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "luca_vildoza = pd.DataFrame({ \"season\": [2021-22],\n",
    "                                         \"team_id\": [\"MIL\"], \n",
    "                                         \"player_dir\": [\"/players/v/vildolu01.html\"], \n",
    "                                         \"per\":[17.9]})\n",
    "season_player_per = pd.concat([pd.read_parquet('PER_table.parquet.gzip'), pd.read_parquet('missing_players.parquet.gzip') , luca_vildoza], ignore_index = True)\n",
    "# season_player_per.drop_duplicates(subset = [\"player_dir\"], keep = \"first\")\n",
    "# season_player_per.to_csv(\"seasons_per_s.csv\", index=False)\n",
    "#need to remove season pers before the year 2015\n",
    "season_player_per = season_player_per[season_player_per[\"season\"].isin([\"2014-15\", \"2015-16\", \"2016-17\", \"2017-18\", \"2018-19\", \"2019-20\", \"2020-21\", \"2021-22\"])]\n",
    "#this list is larger because of trades/transfers etc\n",
    "season_player_per.to_csv(\"seasons_per_s.csv\", index=False)\n",
    "season_player_per"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Team</th>\n",
       "      <th>team_dir</th>\n",
       "      <th>Player</th>\n",
       "      <th>player_dir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015</td>\n",
       "      <td>Golden State Warriors</td>\n",
       "      <td>/teams/GSW/2015.html</td>\n",
       "      <td>Leandro Barbosa</td>\n",
       "      <td>/players/b/barbole01.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015</td>\n",
       "      <td>Golden State Warriors</td>\n",
       "      <td>/teams/GSW/2015.html</td>\n",
       "      <td>Harrison Barnes</td>\n",
       "      <td>/players/b/barneha02.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>Golden State Warriors</td>\n",
       "      <td>/teams/GSW/2015.html</td>\n",
       "      <td>Andrew Bogut</td>\n",
       "      <td>/players/b/bogutan01.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015</td>\n",
       "      <td>Golden State Warriors</td>\n",
       "      <td>/teams/GSW/2015.html</td>\n",
       "      <td>Stephen Curry</td>\n",
       "      <td>/players/c/curryst01.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015</td>\n",
       "      <td>Golden State Warriors</td>\n",
       "      <td>/teams/GSW/2015.html</td>\n",
       "      <td>Festus Ezeli</td>\n",
       "      <td>/players/e/ezelife01.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4804</th>\n",
       "      <td>2022</td>\n",
       "      <td>Portland Trail Blazers</td>\n",
       "      <td>/teams/POR/2022.html</td>\n",
       "      <td>Tony Snell</td>\n",
       "      <td>/players/s/snellto01.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4805</th>\n",
       "      <td>2022</td>\n",
       "      <td>Portland Trail Blazers</td>\n",
       "      <td>/teams/POR/2022.html</td>\n",
       "      <td>Trendon Watford</td>\n",
       "      <td>/players/w/watfotr01.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4806</th>\n",
       "      <td>2022</td>\n",
       "      <td>Portland Trail Blazers</td>\n",
       "      <td>/teams/POR/2022.html</td>\n",
       "      <td>Brandon Williams</td>\n",
       "      <td>/players/w/willibr03.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4807</th>\n",
       "      <td>2022</td>\n",
       "      <td>Portland Trail Blazers</td>\n",
       "      <td>/teams/POR/2022.html</td>\n",
       "      <td>Justise Winslow</td>\n",
       "      <td>/players/w/winslju01.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4808</th>\n",
       "      <td>2022</td>\n",
       "      <td>Portland Trail Blazers</td>\n",
       "      <td>/teams/POR/2022.html</td>\n",
       "      <td>Cody Zeller</td>\n",
       "      <td>/players/z/zelleco01.html</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4809 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Year                    Team              team_dir            Player  \\\n",
       "0     2015   Golden State Warriors  /teams/GSW/2015.html   Leandro Barbosa   \n",
       "1     2015   Golden State Warriors  /teams/GSW/2015.html   Harrison Barnes   \n",
       "2     2015   Golden State Warriors  /teams/GSW/2015.html      Andrew Bogut   \n",
       "3     2015   Golden State Warriors  /teams/GSW/2015.html     Stephen Curry   \n",
       "4     2015   Golden State Warriors  /teams/GSW/2015.html      Festus Ezeli   \n",
       "...    ...                     ...                   ...               ...   \n",
       "4804  2022  Portland Trail Blazers  /teams/POR/2022.html        Tony Snell   \n",
       "4805  2022  Portland Trail Blazers  /teams/POR/2022.html   Trendon Watford   \n",
       "4806  2022  Portland Trail Blazers  /teams/POR/2022.html  Brandon Williams   \n",
       "4807  2022  Portland Trail Blazers  /teams/POR/2022.html   Justise Winslow   \n",
       "4808  2022  Portland Trail Blazers  /teams/POR/2022.html       Cody Zeller   \n",
       "\n",
       "                     player_dir  \n",
       "0     /players/b/barbole01.html  \n",
       "1     /players/b/barneha02.html  \n",
       "2     /players/b/bogutan01.html  \n",
       "3     /players/c/curryst01.html  \n",
       "4     /players/e/ezelife01.html  \n",
       "...                         ...  \n",
       "4804  /players/s/snellto01.html  \n",
       "4805  /players/w/watfotr01.html  \n",
       "4806  /players/w/willibr03.html  \n",
       "4807  /players/w/winslju01.html  \n",
       "4808  /players/z/zelleco01.html  \n",
       "\n",
       "[4809 rows x 5 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "season_rosters = pd.read_pickle(\"df.pickle\", compression='infer')\n",
    "season_rosters "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#final dataframes season_per_s.csv and season_rosters.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# next step get team stats- how are we defining team stats \n",
    "#we need team stats for each game player over the regular season by each team. \n",
    "\n",
    "#1 scrape season matchups from https://www.basketball-reference.com/leagues/NBA_2015_games-MONTH.html (OCTOBER- APRIL(PLAYOFFS))\n",
    "months = [\"october\", \"november\", \"december\", \"january\", \"february\", \"march\", \"april\"]\n",
    "f\"https://www.basketball-reference.com/leagues/NBA_2015_games-{month}.html\"\n",
    "for month in month:\n",
    "schedule_table = soup.find('table', attrs={'id':'schedule'})\n",
    "this_game = adv_table.tbody.findAll(\"tr\")\n",
    "####### make sure its before the playoffs row in april \n",
    "save team abreviations from link \"/team/TEAM ID/year.html, score? home or away \n",
    "<!-- ####### save arena, team as home or away score  -->\n",
    "\n",
    "#2 USE BOX SCORE LINK TO GET INDIVIDUAL GAME STAS \n",
    "EX. https://www.basketball-reference.com/boxscores/201504010CHO.html 201504010CHO- DIFFERENT FOR EACH GAME \n",
    "\n",
    "####### use team_id's to identify team stats table from the game this table also has player stats if we decde to use them \n",
    "ex. soup.find('table', attrs={'id':\"box-TEAM_ID-game-basic\"})\n",
    "get team stats from the tfoot tag\n",
    "\n",
    "#3 save data - probably should do this in seasonal increments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_season_schedule(filename, seasons = [2015]):\n",
    "    season_schedule_table = pd.DataFrame(columns = [\"date\", \"away_team_id\", \"home_team_id\", \"arena\", \"link\"])\n",
    "    months = [\"october\", \"november\", \"december\", \"january\", \"february\", \"march\", \"april\"]\n",
    "    for year in seasons:\n",
    "        for month in months:\n",
    "            month_schedule = f\"https://www.basketball-reference.com/leagues/NBA_{year}_games-{month}.html\"\n",
    "            print(month_schedule)\n",
    "            time.sleep(random.randint(2, 6))\n",
    "            month_schedule_link = urlopen(month_schedule)\n",
    "            soup = BeautifulSoup(month_schedule_link, features=\"lxml\")\n",
    "            schedule_table = soup.find('table', attrs={'id':'schedule'})\n",
    "            games = schedule_table.tbody.findAll(\"tr\")\n",
    "            dates = []\n",
    "            away_team_ids = []\n",
    "            home_team_ids = []\n",
    "            arenas = []\n",
    "            links = []\n",
    "            for game in games:\n",
    "            #avoinding playoffs schedule\n",
    "                if game.th.string == \"Playoffs\":\n",
    "                    season_month = pd.DataFrame({\"date\": dates,\n",
    "                                         \"away_team_id\": away_team_ids, \n",
    "                                         \"home_team_id\": home_team_ids, \n",
    "                                          \"arena\":arenas,\n",
    "                                         \"link\":links\n",
    "                                        })\n",
    "                    break\n",
    "                    \n",
    "                other_stats = game.findAll(\"td\")\n",
    "                date = game.th.a.string\n",
    "                dates.append(date)\n",
    "                away_team = other_stats[1].a.get('href')[7:10]\n",
    "                away_team_ids.append(away_team)\n",
    "                home_team = other_stats[3].a.get('href')[7:10]\n",
    "                home_team_ids.append(home_team)\n",
    "                boxscore = other_stats[5].a.get('href')\n",
    "                links.append(boxscore)\n",
    "                arena = other_stats[8].string\n",
    "                arenas.append(arena)\n",
    "            season_month = pd.DataFrame({\"date\": dates,\n",
    "                                         \"away_team_id\": away_team_ids, \n",
    "                                         \"home_team_id\": home_team_ids, \n",
    "                                          \"arena\":arenas,\n",
    "                                         \"link\":links\n",
    "                                        })\n",
    "            try:\n",
    "                name_of_file = f\"{filename}.parquet.gzip\"\n",
    "                season_games = pd.concat([pd.read_parquet(name_of_file), season_month], ignore_index = True)\n",
    "                season_games.to_parquet(name_of_file)              \n",
    "            except:\n",
    "                name_of_file = f\"{filename}.parquet.gzip\"\n",
    "                season_month.to_parquet(name_of_file)\n",
    "            print(month, \"completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.basketball-reference.com/leagues/NBA_2015_games-october.html\n",
      "october completed\n",
      "https://www.basketball-reference.com/leagues/NBA_2015_games-november.html\n",
      "november completed\n",
      "https://www.basketball-reference.com/leagues/NBA_2015_games-december.html\n",
      "december completed\n",
      "https://www.basketball-reference.com/leagues/NBA_2015_games-january.html\n",
      "january completed\n",
      "https://www.basketball-reference.com/leagues/NBA_2015_games-february.html\n",
      "february completed\n",
      "https://www.basketball-reference.com/leagues/NBA_2015_games-march.html\n",
      "march completed\n",
      "https://www.basketball-reference.com/leagues/NBA_2015_games-april.html\n",
      "april completed\n"
     ]
    }
   ],
   "source": [
    "# 2015 to start \n",
    "# years = [2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022]\n",
    "seasons = [2015]\n",
    "get_season_schedule(str(seasons), seasons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>away_team_id</th>\n",
       "      <th>home_team_id</th>\n",
       "      <th>arena</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tue, Oct 28, 2014</td>\n",
       "      <td>ORL</td>\n",
       "      <td>NOP</td>\n",
       "      <td>Smoothie King Center</td>\n",
       "      <td>/boxscores/201410280NOP.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tue, Oct 28, 2014</td>\n",
       "      <td>DAL</td>\n",
       "      <td>SAS</td>\n",
       "      <td>AT&amp;T Center</td>\n",
       "      <td>/boxscores/201410280SAS.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tue, Oct 28, 2014</td>\n",
       "      <td>HOU</td>\n",
       "      <td>LAL</td>\n",
       "      <td>STAPLES Center</td>\n",
       "      <td>/boxscores/201410280LAL.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wed, Oct 29, 2014</td>\n",
       "      <td>MIL</td>\n",
       "      <td>CHO</td>\n",
       "      <td>Time Warner Cable Arena</td>\n",
       "      <td>/boxscores/201410290CHO.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wed, Oct 29, 2014</td>\n",
       "      <td>PHI</td>\n",
       "      <td>IND</td>\n",
       "      <td>Bankers Life Fieldhouse</td>\n",
       "      <td>/boxscores/201410290IND.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2575</th>\n",
       "      <td>Wed, Apr 15, 2015</td>\n",
       "      <td>DET</td>\n",
       "      <td>NYK</td>\n",
       "      <td>Madison Square Garden (IV)</td>\n",
       "      <td>/boxscores/201504150NYK.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2576</th>\n",
       "      <td>Wed, Apr 15, 2015</td>\n",
       "      <td>MIA</td>\n",
       "      <td>PHI</td>\n",
       "      <td>Wells Fargo Center</td>\n",
       "      <td>/boxscores/201504150PHI.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2577</th>\n",
       "      <td>Wed, Apr 15, 2015</td>\n",
       "      <td>IND</td>\n",
       "      <td>MEM</td>\n",
       "      <td>FedEx Forum</td>\n",
       "      <td>/boxscores/201504150MEM.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2578</th>\n",
       "      <td>Wed, Apr 15, 2015</td>\n",
       "      <td>DEN</td>\n",
       "      <td>GSW</td>\n",
       "      <td>Oracle Arena</td>\n",
       "      <td>/boxscores/201504150GSW.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2579</th>\n",
       "      <td>Wed, Apr 15, 2015</td>\n",
       "      <td>SAC</td>\n",
       "      <td>LAL</td>\n",
       "      <td>STAPLES Center</td>\n",
       "      <td>/boxscores/201504150LAL.html</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2580 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   date away_team_id home_team_id                       arena  \\\n",
       "0     Tue, Oct 28, 2014          ORL          NOP        Smoothie King Center   \n",
       "1     Tue, Oct 28, 2014          DAL          SAS                 AT&T Center   \n",
       "2     Tue, Oct 28, 2014          HOU          LAL              STAPLES Center   \n",
       "3     Wed, Oct 29, 2014          MIL          CHO     Time Warner Cable Arena   \n",
       "4     Wed, Oct 29, 2014          PHI          IND     Bankers Life Fieldhouse   \n",
       "...                 ...          ...          ...                         ...   \n",
       "2575  Wed, Apr 15, 2015          DET          NYK  Madison Square Garden (IV)   \n",
       "2576  Wed, Apr 15, 2015          MIA          PHI          Wells Fargo Center   \n",
       "2577  Wed, Apr 15, 2015          IND          MEM                 FedEx Forum   \n",
       "2578  Wed, Apr 15, 2015          DEN          GSW                Oracle Arena   \n",
       "2579  Wed, Apr 15, 2015          SAC          LAL              STAPLES Center   \n",
       "\n",
       "                              link  \n",
       "0     /boxscores/201410280NOP.html  \n",
       "1     /boxscores/201410280SAS.html  \n",
       "2     /boxscores/201410280LAL.html  \n",
       "3     /boxscores/201410290CHO.html  \n",
       "4     /boxscores/201410290IND.html  \n",
       "...                            ...  \n",
       "2575  /boxscores/201504150NYK.html  \n",
       "2576  /boxscores/201504150PHI.html  \n",
       "2577  /boxscores/201504150MEM.html  \n",
       "2578  /boxscores/201504150GSW.html  \n",
       "2579  /boxscores/201504150LAL.html  \n",
       "\n",
       "[2580 rows x 5 columns]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_of_file = f\"{str(seasons)}.parquet.gzip\"\n",
    "season_games = pd.read_parquet(name_of_file)\n",
    "season_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_game_stats(dataframe, filename):\n",
    "    count = 0 \n",
    "    for game in dataframe.iterrows():\n",
    "        game = game[1]\n",
    "        home_team_id = game[\"home_team_id\"]\n",
    "        away_team_id = game[\"away_team_id\"]\n",
    "        arena = game[\"arena\"]\n",
    "        ext = game[\"link\"]\n",
    "        box_score_url = f\"https://www.basketball-reference.com{ext}\"\n",
    "        time.sleep(random.randint(2, 6))\n",
    "        open_link = urlopen(box_score_url)\n",
    "        soup = BeautifulSoup(open_link, features=\"lxml\")\n",
    "        home_stats = soup.find('table', attrs={'id':f\"box-{home_team_id}-game-basic\"}).tfoot.tr\n",
    "        home_fg = home_stats.find('td', attrs = {'data-stat': 'fg'}).string\n",
    "        home_fga = home_stats.find('td', attrs = {'data-stat': 'fga'}).string\n",
    "        home_fg_pct = home_stats.find('td', attrs = {'data-stat': 'fg_pct'}).string\n",
    "        home_fg3 = home_stats.find('td', attrs = {'data-stat': 'fg3'}).string\n",
    "        home_fg3a = home_stats.find('td', attrs = {'data-stat': 'fg3a'}).string\n",
    "        home_fg3_pct = home_stats.find('td', attrs = {'data-stat': 'fg3_pct'}).string\n",
    "        home_ft = home_stats.find('td', attrs = {'data-stat': 'ft'}).string\n",
    "        home_fta = home_stats.find('td', attrs = {'data-stat': 'fta'}).string\n",
    "        home_ft_pct = home_stats.find('td', attrs = {'data-stat': 'ft_pct'}).string\n",
    "        home_orb = home_stats.find('td', attrs = {'data-stat': 'orb'}).string\n",
    "        home_drb = home_stats.find('td', attrs = {'data-stat': 'drb'}).string\n",
    "        home_trb = home_stats.find('td', attrs = {'data-stat': 'trb'}).string\n",
    "        home_ast = home_stats.find('td', attrs = {'data-stat': 'ast'}).string\n",
    "        home_stl = home_stats.find('td', attrs = {'data-stat': 'stl'}).string\n",
    "        home_blk = home_stats.find('td', attrs = {'data-stat': 'blk'}).string\n",
    "        home_tov = home_stats.find('td', attrs = {'data-stat': 'tov'}).string\n",
    "        home_pf = home_stats.find('td', attrs = {'data-stat': 'pf'}).string\n",
    "        home_pts = home_stats.find('td', attrs = {'data-stat': 'pts'}).string\n",
    "        \n",
    "        away_stats = soup.find('table', attrs={'id':f\"box-{away_team_id}-game-basic\"}).tfoot.tr\n",
    "        away_fg = away_stats.find('td', attrs = {'data-stat': 'fg'}).string\n",
    "        away_fga = away_stats.find('td', attrs = {'data-stat': 'fga'}).string\n",
    "        away_fg_pct = away_stats.find('td', attrs = {'data-stat': 'fg_pct'}).string\n",
    "        away_fg3 = away_stats.find('td', attrs = {'data-stat': 'fg3'}).string\n",
    "        away_fg3a = away_stats.find('td', attrs = {'data-stat': 'fg3a'}).string\n",
    "        away_fg3_pct = away_stats.find('td', attrs = {'data-stat': 'fg3_pct'}).string\n",
    "        away_ft = away_stats.find('td', attrs = {'data-stat': 'ft'}).string\n",
    "        away_fta = away_stats.find('td', attrs = {'data-stat': 'fta'}).string\n",
    "        away_ft_pct = away_stats.find('td', attrs = {'data-stat': 'ft_pct'}).string\n",
    "        away_orb = away_stats.find('td', attrs = {'data-stat': 'orb'}).string\n",
    "        away_drb = away_stats.find('td', attrs = {'data-stat': 'drb'}).string\n",
    "        away_trb = away_stats.find('td', attrs = {'data-stat': 'trb'}).string\n",
    "        away_ast = away_stats.find('td', attrs = {'data-stat': 'ast'}).string\n",
    "        away_stl = away_stats.find('td', attrs = {'data-stat': 'stl'}).string\n",
    "        away_blk = away_stats.find('td', attrs = {'data-stat': 'blk'}).string\n",
    "        away_tov = away_stats.find('td', attrs = {'data-stat': 'tov'}).string\n",
    "        away_pf = away_stats.find('td', attrs = {'data-stat': 'pf'}).string\n",
    "        away_pts = away_stats.find('td', attrs = {'data-stat': 'pts'}).string\n",
    "    \n",
    "        game_stats = pd.DataFrame({\n",
    "        \"home_team\":[home_team_id],\n",
    "        \"home_fg\":[home_fg], \n",
    "        \"home_fga\":[home_fga], \n",
    "        \"home_fg_pct\":[home_fg_pct], \n",
    "        \"home_fg3\":[home_fg3], \n",
    "        \"home_fg3a\":[home_fg3a], \n",
    "        \"home_fg3_pct\":[home_fg3_pct], \n",
    "        \"home_ft\":[home_ft], \n",
    "        \"home_fta\":[home_fta], \n",
    "        \"home_ft_pct\":[home_ft_pct], \n",
    "        \"home_orb\":[home_orb], \n",
    "        \"home_drb\":[home_drb],\n",
    "        \"home_trb\":[home_trb],\n",
    "        \"home_ast\":[home_ast],\n",
    "        \"home_stl\":[home_stl],\n",
    "        \"home_blk\":[home_blk],\n",
    "        \"home_tov\":[home_tov],\n",
    "        \"home_pf\":[home_pf],\n",
    "        \"home_pts\":[home_pts],\n",
    "        \"away_team\":[away_team_id],\n",
    "        \"away_fg\":[away_fg], \n",
    "        \"away_fga\":[away_fga], \n",
    "        \"away_fg_pct\":[away_fg_pct], \n",
    "        \"away_fg3\":[away_fg3], \n",
    "        \"away_fg3a\":[away_fg3a], \n",
    "        \"away_fg3_pct\":[away_fg3_pct], \n",
    "        \"away_ft\":[away_ft], \n",
    "        \"away_fta\":[away_fta], \n",
    "        \"away_ft_pct\":[away_ft_pct], \n",
    "        \"away_orb\":[away_orb], \n",
    "        \"away_drb\":[away_drb],\n",
    "        \"away_trb\":[away_trb],\n",
    "        \"away_ast\":[away_ast],\n",
    "        \"away_stl\":[away_stl],\n",
    "        \"away_blk\":[away_blk],\n",
    "        \"away_tov\":[away_tov],\n",
    "        \"away_pf\":[away_pf],\n",
    "        \"away_pts\":[away_pts],\n",
    "        \"arena\": [arena]})\n",
    "        if count % 100 == 0:\n",
    "            print(count)   \n",
    "            try:\n",
    "                name_of_file = f\"{filename}.parquet.gzip\"\n",
    "                game_stats = pd.concat([pd.read_parquet(name_of_file), game_stats], ignore_index = True)\n",
    "                game_stats.to_parquet(name_of_file)              \n",
    "            except:\n",
    "                name_of_file = f\"{filename}.parquet.gzip\"\n",
    "                game_stats.to_parquet(name_of_file)\n",
    "            count+=1\n",
    "    name_of_file = f\"{filename}.parquet.gzip\"\n",
    "    game_stats = pd.concat([pd.read_parquet(name_of_file), game_stats], ignore_index = True)\n",
    "    game_stats.to_parquet(name_of_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "get_game_stats(season_games, \"2014-15_game_stats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 276\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2-4 .parquet.gzip files should be saved in the current directory!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 276\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 256\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[0;32m--> 256\u001b[0m     my_vol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvolume number:\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m     my_vol\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    259\u001b[0m     Volume_1 \u001b[38;5;241m=\u001b[39m  [\u001b[38;5;241m2015\u001b[39m, \u001b[38;5;241m2016\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: ''"
     ]
    }
   ],
   "source": [
    "# required libraries\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "def get_season_schedule(filename, seasons = [2015]):\n",
    "    '''\n",
    "    Gets the season schedule (games played throughout the season) up until the playoffs. \n",
    "    creates a dataframe to inform us of any potential errors and allows code to not break because of errors\n",
    "    '''\n",
    "    season_schedule_table = pd.DataFrame(columns = [\"season\", \"date\", \"away_team_id\", \"home_team_id\", \"arena\", \"link\"])\n",
    "    months = [\"october\", \"november\", \"december\", \"january\", \"february\", \"march\", \"april\"]\n",
    "    for year in seasons:\n",
    "        print(f\"getting {year} data....\")\n",
    "        for month in months:\n",
    "            month_schedule = f\"https://www.basketball-reference.com/leagues/NBA_{year}_games-{month}.html\"\n",
    "            time.sleep(random.randint(2, 6))\n",
    "            #checks whether the link is valid and lets us know if any connections didnt work by saving to erros df. some errors here are good!\n",
    "            try:\n",
    "                month_schedule_link = urlopen(month_schedule)\n",
    "                soup = BeautifulSoup(month_schedule_link, features=\"lxml\")\n",
    "            except:\n",
    "                #the month may not have been a part of the season/year so each year will have some error months. this is really here for the covid seasons and high level error checking\n",
    "                errors = pd.DataFrame({\"season\": [year], \"month\":[month], \"error\": [\"invalid season link\"]})\n",
    "                try:\n",
    "                    name_of_file = f\"{filename}_error.parquet.gzip\"\n",
    "                    errors = pd.concat([pd.read_parquet(name_of_file), errors], ignore_index = True)\n",
    "                    errors.to_parquet(name_of_file)              \n",
    "                except:\n",
    "                    name_of_file = f\"{filename}_error.parquet.gzip\"\n",
    "                    errors.to_parquet(name_of_file)\n",
    "                continue\n",
    "            try:    \n",
    "                schedule_table = soup.find('table', attrs={'id':'schedule'})\n",
    "                games = schedule_table.tbody.findAll(\"tr\")\n",
    "                season = []\n",
    "                dates = []\n",
    "                away_team_ids = []\n",
    "                home_team_ids = []\n",
    "                arenas = []\n",
    "                links = []\n",
    "                for game in games:\n",
    "                #avoinding playoffs schedule\n",
    "                    if game.th.string == \"Playoffs\":\n",
    "                        break\n",
    "                    season.append(year)\n",
    "                    other_stats = game.findAll(\"td\")\n",
    "                    date = game.th.a.string\n",
    "                    dates.append(date)\n",
    "                    away_team = other_stats[1].a.get('href')[7:10]\n",
    "                    away_team_ids.append(away_team)\n",
    "                    home_team = other_stats[3].a.get('href')[7:10]\n",
    "                    home_team_ids.append(home_team)\n",
    "                    boxscore = other_stats[5].a.get('href')\n",
    "                    links.append(boxscore)\n",
    "                    arena = other_stats[8].string\n",
    "                    arenas.append(arena)\n",
    "                season_month = pd.DataFrame({\"season\": season,\n",
    "                                             \"date\": dates,\n",
    "                                             \"away_team_id\": away_team_ids, \n",
    "                                             \"home_team_id\": home_team_ids, \n",
    "                                              \"arena\":arenas,\n",
    "                                             \"link\":links\n",
    "                                            })\n",
    "            except:\n",
    "                #table error most likely 2020 april, where games werent played\n",
    "                errors = pd.DataFrame({\"season\": [year], \"month\":[month], \"error\": [\"unable to scrape table\"]})\n",
    "                try:\n",
    "                    name_of_file = f\"{filename}_error.parquet.gzip\"\n",
    "                    errors = pd.concat([pd.read_parquet(name_of_file), errors], ignore_index = True)\n",
    "                    errors.to_parquet(name_of_file)              \n",
    "                except:\n",
    "                    name_of_file = f\"{filename}_error.parquet.gzip\"\n",
    "                    errors.to_parquet(name_of_file)\n",
    "                continue\n",
    "            # try to append to an existing file, if not exist create it \n",
    "            try:\n",
    "                name_of_file = f\"{filename}.parquet.gzip\"\n",
    "                season_games = pd.concat([pd.read_parquet(name_of_file), season_month], ignore_index = True)\n",
    "                season_games.to_parquet(name_of_file)              \n",
    "            except:\n",
    "                name_of_file = f\"{filename}.parquet.gzip\"\n",
    "                season_month.to_parquet(name_of_file)\n",
    "            print(month, \"completed\")\n",
    "    return pd.read_parquet(name_of_file)\n",
    "\n",
    "def get_game_stats(dataframe, filename):\n",
    "    \"\"\"\n",
    "    gets individual game statistics given a seasons games as a pandas df \n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    flag = 0\n",
    "    print(\"getitng individual game stats\", end = \" \")\n",
    "    for game in dataframe.iterrows():\n",
    "        print('-', end=\"\") \n",
    "        game = game[1]\n",
    "        home_team_id = game[\"home_team_id\"]\n",
    "        away_team_id = game[\"away_team_id\"]\n",
    "        arena = game[\"arena\"]\n",
    "        ext = game[\"link\"]\n",
    "        this_season = game[\"season\"]\n",
    "        # if count % 100 == 0:\n",
    "        #     if count!=0:\n",
    "        #         print(\"\\nscraped \", len(pd.read_parquet(f\"{filename}.parquet.gzip\")), f\" games from {this_season}\")\n",
    "        try:\n",
    "            box_score_url = f\"https://www.basketball-reference.com{ext}\"\n",
    "            time.sleep(random.randint(2, 6))\n",
    "            open_link = urlopen(box_score_url)\n",
    "            soup = BeautifulSoup(open_link, features=\"lxml\")\n",
    "            print(\"finished_try.............................................................\")\n",
    "        except Exception as e: \n",
    "            print(e)\n",
    "            error = pd.DataFrame({\"season\": game[\"season\"], \n",
    "            \"date\": game[\"date\"], \n",
    "            \"away_team_id\": away_team_id, \n",
    "            \"home_team_id\": home_team_id, \n",
    "            \"arena\": arena, \n",
    "            \"link\": ext, \n",
    "            \"error\": [\"404: invalid game link\"]})\n",
    "            try:\n",
    "                name_of_file = f\"{filename}_error.parquet.gzip\"\n",
    "                errors = pd.concat([pd.read_parquet(name_of_file), error], ignore_index = True)\n",
    "                errors.to_parquet(name_of_file)              \n",
    "            except:\n",
    "                name_of_file = f\"{filename}_error.parquet.gzip\"\n",
    "                error.to_parquet(name_of_file)\n",
    "            continue\n",
    "        try:\n",
    "            home_stats = soup.find('table', attrs={'id':f\"box-{home_team_id}-game-basic\"}).tfoot.tr\n",
    "            home_fg = home_stats.find('td', attrs = {'data-stat': 'fg'}).string\n",
    "            home_fga = home_stats.find('td', attrs = {'data-stat': 'fga'}).string\n",
    "            home_fg_pct = home_stats.find('td', attrs = {'data-stat': 'fg_pct'}).string\n",
    "            home_fg3 = home_stats.find('td', attrs = {'data-stat': 'fg3'}).string\n",
    "            home_fg3a = home_stats.find('td', attrs = {'data-stat': 'fg3a'}).string\n",
    "            home_fg3_pct = home_stats.find('td', attrs = {'data-stat': 'fg3_pct'}).string\n",
    "            home_ft = home_stats.find('td', attrs = {'data-stat': 'ft'}).string\n",
    "            home_fta = home_stats.find('td', attrs = {'data-stat': 'fta'}).string\n",
    "            home_ft_pct = home_stats.find('td', attrs = {'data-stat': 'ft_pct'}).string\n",
    "            home_orb = home_stats.find('td', attrs = {'data-stat': 'orb'}).string\n",
    "            home_drb = home_stats.find('td', attrs = {'data-stat': 'drb'}).string\n",
    "            home_trb = home_stats.find('td', attrs = {'data-stat': 'trb'}).string\n",
    "            home_ast = home_stats.find('td', attrs = {'data-stat': 'ast'}).string\n",
    "            home_stl = home_stats.find('td', attrs = {'data-stat': 'stl'}).string\n",
    "            home_blk = home_stats.find('td', attrs = {'data-stat': 'blk'}).string\n",
    "            home_tov = home_stats.find('td', attrs = {'data-stat': 'tov'}).string\n",
    "            home_pf = home_stats.find('td', attrs = {'data-stat': 'pf'}).string\n",
    "            home_pts = home_stats.find('td', attrs = {'data-stat': 'pts'}).string\n",
    "\n",
    "            away_stats = soup.find('table', attrs={'id':f\"box-{away_team_id}-game-basic\"}).tfoot.tr\n",
    "            away_fg = away_stats.find('td', attrs = {'data-stat': 'fg'}).string\n",
    "            away_fga = away_stats.find('td', attrs = {'data-stat': 'fga'}).string\n",
    "            away_fg_pct = away_stats.find('td', attrs = {'data-stat': 'fg_pct'}).string\n",
    "            away_fg3 = away_stats.find('td', attrs = {'data-stat': 'fg3'}).string\n",
    "            away_fg3a = away_stats.find('td', attrs = {'data-stat': 'fg3a'}).string\n",
    "            away_fg3_pct = away_stats.find('td', attrs = {'data-stat': 'fg3_pct'}).string\n",
    "            away_ft = away_stats.find('td', attrs = {'data-stat': 'ft'}).string\n",
    "            away_fta = away_stats.find('td', attrs = {'data-stat': 'fta'}).string\n",
    "            away_ft_pct = away_stats.find('td', attrs = {'data-stat': 'ft_pct'}).string\n",
    "            away_orb = away_stats.find('td', attrs = {'data-stat': 'orb'}).string\n",
    "            away_drb = away_stats.find('td', attrs = {'data-stat': 'drb'}).string\n",
    "            away_trb = away_stats.find('td', attrs = {'data-stat': 'trb'}).string\n",
    "            away_ast = away_stats.find('td', attrs = {'data-stat': 'ast'}).string\n",
    "            away_stl = away_stats.find('td', attrs = {'data-stat': 'stl'}).string\n",
    "            away_blk = away_stats.find('td', attrs = {'data-stat': 'blk'}).string\n",
    "            away_tov = away_stats.find('td', attrs = {'data-stat': 'tov'}).string\n",
    "            away_pf = away_stats.find('td', attrs = {'data-stat': 'pf'}).string\n",
    "            away_pts = away_stats.find('td', attrs = {'data-stat': 'pts'}).string\n",
    "\n",
    "            game_stats = pd.DataFrame({\n",
    "            \"home_team\":[home_team_id],\n",
    "            \"home_fg\":[home_fg], \n",
    "            \"home_fga\":[home_fga], \n",
    "            \"home_fg_pct\":[home_fg_pct], \n",
    "            \"home_fg3\":[home_fg3], \n",
    "            \"home_fg3a\":[home_fg3a], \n",
    "            \"home_fg3_pct\":[home_fg3_pct], \n",
    "            \"home_ft\":[home_ft], \n",
    "            \"home_fta\":[home_fta], \n",
    "            \"home_ft_pct\":[home_ft_pct], \n",
    "            \"home_orb\":[home_orb], \n",
    "            \"home_drb\":[home_drb],\n",
    "            \"home_trb\":[home_trb],\n",
    "            \"home_ast\":[home_ast],\n",
    "            \"home_stl\":[home_stl],\n",
    "            \"home_blk\":[home_blk],\n",
    "            \"home_tov\":[home_tov],\n",
    "            \"home_pf\":[home_pf],\n",
    "            \"home_pts\":[home_pts],\n",
    "            \"away_team\":[away_team_id],\n",
    "            \"away_fg\":[away_fg], \n",
    "            \"away_fga\":[away_fga], \n",
    "            \"away_fg_pct\":[away_fg_pct], \n",
    "            \"away_fg3\":[away_fg3], \n",
    "            \"away_fg3a\":[away_fg3a], \n",
    "            \"away_fg3_pct\":[away_fg3_pct], \n",
    "            \"away_ft\":[away_ft], \n",
    "            \"away_fta\":[away_fta], \n",
    "            \"away_ft_pct\":[away_ft_pct], \n",
    "            \"away_orb\":[away_orb], \n",
    "            \"away_drb\":[away_drb],\n",
    "            \"away_trb\":[away_trb],\n",
    "            \"away_ast\":[away_ast],\n",
    "            \"away_stl\":[away_stl],\n",
    "            \"away_blk\":[away_blk],\n",
    "            \"away_tov\":[away_tov],\n",
    "            \"away_pf\":[away_pf],\n",
    "            \"away_pts\":[away_pts],\n",
    "            \"arena\": [arena]})\n",
    "            \n",
    "        except:\n",
    "            \n",
    "            error = pd.DataFrame({\"season\": game[\"season\"], \n",
    "            \"date\": game[\"date\"], \n",
    "            \"away_team_id\": away_team_id, \n",
    "            \"home_team_id\": home_team_id, \n",
    "            \"arena\": arena, \n",
    "            \"link\": ext, \n",
    "            \"error\": [\"error scraping table\"]})\n",
    "            flag = 1\n",
    "            print(\"error\", error)\n",
    "            try:\n",
    "                name_of_file = f\"{filename}_error.parquet.gzip\"\n",
    "                errors = pd.concat([pd.read_parquet(name_of_file), error], ignore_index = True)\n",
    "                errors.to_parquet(name_of_file)              \n",
    "            except:\n",
    "                name_of_file = f\"{filename}_error.parquet.gzip\"\n",
    "                error.to_parquet(name_of_file)\n",
    "            continue\n",
    "            \n",
    "        if count % 100 == 0 and count != 0:\n",
    "            try:\n",
    "                name_of_file = f\"{filename}.parquet.gzip\"\n",
    "                game_stats = pd.concat([pd.read_parquet(name_of_file), game_stats], ignore_index = True)\n",
    "                game_stats.to_parquet(name_of_file)\n",
    "                print(f\"\\nteam data for {len(game_stats)} teams collected in the {this_season}\")\n",
    "            except:\n",
    "                name_of_file = f\"{filename}.parquet.gzip\"\n",
    "                game_stats.to_parquet(name_of_file)\n",
    "        count+=1\n",
    "    try:\n",
    "        name_of_file = f\"{filename}.parquet.gzip\"\n",
    "        game_stats = pd.concat([pd.read_parquet(name_of_file), game_stats], ignore_index = True)\n",
    "        game_stats.to_parquet(name_of_file)             \n",
    "    except:\n",
    "        name_of_file = f\"{filename}.parquet.gzip\"\n",
    "        game_stats.to_parquet(name_of_file) \n",
    "    if flag == 1:\n",
    "        print(\"errors: \", len(pd.read_parquet(f\"{filename}_error.parquet.gzip\")))\n",
    "    return game_stats\n",
    "\n",
    "\n",
    "def main():\n",
    "    my_vol = int(input(\"volume number:\"))\n",
    "    my_vol-=1\n",
    "    \n",
    "    Volume_1 =  [2015, 2016]\n",
    "    Volume_2 =  [2017, 2018]\n",
    "    Volume_3 =  [2019, 2020]\n",
    "    Volume_4 =  [2021, 2022]\n",
    "    \n",
    "    volumes = [Volume_1, Volume_2, Volume_3, Volume_4]\n",
    "    print(\"getting seasons: \", str(volumes[my_vol]))\n",
    "    \n",
    "    \n",
    "    #gets game schedule of a list of seasons\n",
    "    # get_season_schedule(str(volumes[my_vol]), volumes[my_vol])\n",
    "    name_of_file = f\"{str(volumes[my_vol])}.parquet.gzip\"\n",
    "    season_games = pd.read_parquet(name_of_file)\n",
    "    get_game_stats(season_games, f\"{str(volumes[my_vol])}_game_stats\")\n",
    "    print(\"2-4 .parquet.gzip files should be saved in the current directory!\")\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>date</th>\n",
       "      <th>away_team_id</th>\n",
       "      <th>home_team_id</th>\n",
       "      <th>arena</th>\n",
       "      <th>link</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021</td>\n",
       "      <td>Tue, Dec 22, 2020</td>\n",
       "      <td>GSW</td>\n",
       "      <td>BRK</td>\n",
       "      <td>Barclays Center</td>\n",
       "      <td>/boxscores/202012220BRK.html</td>\n",
       "      <td>404: invalid game link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021</td>\n",
       "      <td>Tue, Dec 22, 2020</td>\n",
       "      <td>LAC</td>\n",
       "      <td>LAL</td>\n",
       "      <td>STAPLES Center</td>\n",
       "      <td>/boxscores/202012220LAL.html</td>\n",
       "      <td>404: invalid game link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021</td>\n",
       "      <td>Wed, Dec 23, 2020</td>\n",
       "      <td>CHO</td>\n",
       "      <td>CLE</td>\n",
       "      <td>Rocket Mortgage Fieldhouse</td>\n",
       "      <td>/boxscores/202012230CLE.html</td>\n",
       "      <td>404: invalid game link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021</td>\n",
       "      <td>Wed, Dec 23, 2020</td>\n",
       "      <td>NYK</td>\n",
       "      <td>IND</td>\n",
       "      <td>Bankers Life Fieldhouse</td>\n",
       "      <td>/boxscores/202012230IND.html</td>\n",
       "      <td>404: invalid game link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021</td>\n",
       "      <td>Wed, Dec 23, 2020</td>\n",
       "      <td>MIA</td>\n",
       "      <td>ORL</td>\n",
       "      <td>Amway Center</td>\n",
       "      <td>/boxscores/202012230ORL.html</td>\n",
       "      <td>404: invalid game link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>2021</td>\n",
       "      <td>Sun, Apr 11, 2021</td>\n",
       "      <td>IND</td>\n",
       "      <td>MEM</td>\n",
       "      <td>FedEx Forum</td>\n",
       "      <td>/boxscores/202104110MEM.html</td>\n",
       "      <td>404: invalid game link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>2021</td>\n",
       "      <td>Sun, Apr 11, 2021</td>\n",
       "      <td>CHI</td>\n",
       "      <td>MIN</td>\n",
       "      <td>Target Center</td>\n",
       "      <td>/boxscores/202104110MIN.html</td>\n",
       "      <td>404: invalid game link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>2021</td>\n",
       "      <td>Sun, Apr 11, 2021</td>\n",
       "      <td>TOR</td>\n",
       "      <td>NYK</td>\n",
       "      <td>Madison Square Garden (IV)</td>\n",
       "      <td>/boxscores/202104110NYK.html</td>\n",
       "      <td>404: invalid game link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>2021</td>\n",
       "      <td>Sun, Apr 11, 2021</td>\n",
       "      <td>DET</td>\n",
       "      <td>LAC</td>\n",
       "      <td>STAPLES Center</td>\n",
       "      <td>/boxscores/202104110LAC.html</td>\n",
       "      <td>404: invalid game link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>2021</td>\n",
       "      <td>Sat, Dec 26, 2020</td>\n",
       "      <td>OKC</td>\n",
       "      <td>CHO</td>\n",
       "      <td>Spectrum Center</td>\n",
       "      <td>/boxscores/202012260CHO.html</td>\n",
       "      <td>404: invalid game link</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>791 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     season               date away_team_id home_team_id  \\\n",
       "0      2021  Tue, Dec 22, 2020          GSW          BRK   \n",
       "1      2021  Tue, Dec 22, 2020          LAC          LAL   \n",
       "2      2021  Wed, Dec 23, 2020          CHO          CLE   \n",
       "3      2021  Wed, Dec 23, 2020          NYK          IND   \n",
       "4      2021  Wed, Dec 23, 2020          MIA          ORL   \n",
       "..      ...                ...          ...          ...   \n",
       "786    2021  Sun, Apr 11, 2021          IND          MEM   \n",
       "787    2021  Sun, Apr 11, 2021          CHI          MIN   \n",
       "788    2021  Sun, Apr 11, 2021          TOR          NYK   \n",
       "789    2021  Sun, Apr 11, 2021          DET          LAC   \n",
       "790    2021  Sat, Dec 26, 2020          OKC          CHO   \n",
       "\n",
       "                          arena                          link  \\\n",
       "0               Barclays Center  /boxscores/202012220BRK.html   \n",
       "1                STAPLES Center  /boxscores/202012220LAL.html   \n",
       "2    Rocket Mortgage Fieldhouse  /boxscores/202012230CLE.html   \n",
       "3       Bankers Life Fieldhouse  /boxscores/202012230IND.html   \n",
       "4                  Amway Center  /boxscores/202012230ORL.html   \n",
       "..                          ...                           ...   \n",
       "786                 FedEx Forum  /boxscores/202104110MEM.html   \n",
       "787               Target Center  /boxscores/202104110MIN.html   \n",
       "788  Madison Square Garden (IV)  /boxscores/202104110NYK.html   \n",
       "789              STAPLES Center  /boxscores/202104110LAC.html   \n",
       "790             Spectrum Center  /boxscores/202012260CHO.html   \n",
       "\n",
       "                      error  \n",
       "0    404: invalid game link  \n",
       "1    404: invalid game link  \n",
       "2    404: invalid game link  \n",
       "3    404: invalid game link  \n",
       "4    404: invalid game link  \n",
       "..                      ...  \n",
       "786  404: invalid game link  \n",
       "787  404: invalid game link  \n",
       "788  404: invalid game link  \n",
       "789  404: invalid game link  \n",
       "790  404: invalid game link  \n",
       "\n",
       "[791 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_parquet(\"[2021, 2022]_game_stats_error.parquet.gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
